{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/sumaiyah/OneDrive - University Of Cambridge/Project/DNN-RE/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LetterRecognition-actual-binary'\n",
    "target_col_name = 'letter'\n",
    "\n",
    "RAW_DATA_PATH = 'raw_data/LetterRecognition.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Recognition Dataset\n",
    "\n",
    "[src](https://archive.ics.uci.edu/ml/datasets/Letter+Recognition)\n",
    "\n",
    "**Multi-classification:**\n",
    "- **Input:** Letters are represented with pixels that have been transformed into 16 attributes. Original Pixel graphics have been transformed to a number of 16 attributes representing special characteristics, 0-15 indicate each attribute. \n",
    "- **Output:** A-Z, The letter being described\n",
    "\n",
    "**Binary classification:**\n",
    "- **Input:** Letters are represented with pixels that have been transformed into 16 attributes. Original Pixel graphics have been transformed to a number of 16 attributes representing special characteristics, 0-15 indicate each attribute. \n",
    "- **Output:** 0 for A, 1 for any other letter\n",
    "\n",
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_letter = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(RAW_DATA_PATH)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of input features\n",
    "feature_col_names = list(raw_data.columns)\n",
    "feature_col_names.remove(target_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data['letter'].isin(['A','Z'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target data\n",
    "# class_0 = A\n",
    "# class_1 = B\n",
    "raw_data[target_col_name].replace({'A':0, 'Z':1}, inplace=True)\n",
    "\n",
    "data = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make class numbers equal, right now theyre v unequal\n",
    "# # Shuffle and get examples from class_1 so len(class_1)==len(class_0)\n",
    "# class_0 = data[data[target_col_name] == 0]\n",
    "# class_1 = data[data[target_col_name] == 1].sample(frac=1).reset_index(drop=True)[0:len(class_0)]\n",
    "\n",
    "# # Shuffle all the data and combine into 1 dataframe\n",
    "# data = pd.concat((class_0, class_1)).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "data[target_col_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate input features and target column\n",
    "X = data.drop(columns=[target_col_name]).values  \n",
    "y = data[target_col_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale input features i.e. scale attributes so that theyre 0-1 so that larger weights do not carry more signifcance in the network\n",
    "scaler = MinMaxScaler() \n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store preprocessed data\n",
    "data = pd.DataFrame(X, columns=feature_col_names)\n",
    "data[target_col_name] = y\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.columns[-1]==target_col_name, 'Target column must be last column in DataFrame'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise new empty dataset folder\n",
    "from model.generation.helpers import init_dataset_dir\n",
    "\n",
    "path_to_data_folder = '../'\n",
    "init_dataset_dir.run(dataset_name=dataset_name, path_to_data_folder=path_to_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../' + dataset_name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "data.to_csv(data_path + 'data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
