{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "def reset_random_seeds():\n",
    "   os.environ['PYTHONHASHSEED']=str(1)\n",
    "   tf.random.set_seed(1)\n",
    "   np.random.seed(1)\n",
    "   python_random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import keras\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import Lambda, Input, Dense, BatchNormalization as BN, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pip install -U imbalanced-learn\n",
    "from imblearn import over_sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hist with 1000 genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('MBdata_33CLINwMiss_1KfGE_1KfCNA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDC                1547\n",
       "ILC                 147\n",
       "IDC+ILC              90\n",
       "IDC-TUB              67\n",
       "IDC-MUC              46\n",
       "IDC-MED              32\n",
       "OTHER_INVASIVE       24\n",
       "DCIS                  9\n",
       "INVASIVE_TUMOUR       9\n",
       "PHYL                  4\n",
       "BENIGN                3\n",
       "?                     2\n",
       "Name: Histological_Type, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['Histological_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_IDC_ILC = raw_data[(raw_data['Histological_Type'] == 'IDC') | (raw_data['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDC    1547\n",
       "ILC     147\n",
       "Name: Histological_Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_IDC_ILC['Histological_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_IDC_ILC_ge = raw_data_IDC_ILC.iloc[:, 34:1034]\n",
    "scaler = MinMaxScaler() \n",
    "raw_data_IDC_ILC_ge = scaler.fit_transform(raw_data_IDC_ILC_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "hist_type = raw_data_IDC_ILC.loc[:,'Histological_Type']\n",
    "hist_type.replace({\"IDC\":0,\"ILC\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(raw_data_IDC_ILC_ge, hist_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_df = raw_data_IDC_ILC.iloc[:, 34:1034]\n",
    "hist_type_df = raw_data_IDC_ILC.loc[:, \"Histological_Type\"]\n",
    "mb_ge_hist_df = pd.concat([genes_df, hist_type_df], axis=1)\n",
    "mb_ge_hist_df.to_csv('MB-GE-Hist.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with imbalanced data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=50, random_state=42,  max_features=.5)\n",
    "random_forest = random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196428571428571\n",
      "[[514   1]\n",
      " [ 44   1]]\n"
     ]
    }
   ],
   "source": [
    "predicted = random_forest.predict(X_test)\n",
    "print(accuracy_score(y_test,predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.5, gamma='auto', probability=True, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC(C=1.5, kernel='rbf',random_state=42,gamma='auto',probability=True)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196428571428571\n",
      "[[515   0]\n",
      " [ 45   0]]\n"
     ]
    }
   ],
   "source": [
    "predicted = svm.predict(X_test)\n",
    "print(accuracy_score(y_test,predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    reset_random_seeds()\n",
    "    \n",
    "    inp = Input(shape=(int_size,))\n",
    "\n",
    "    x = Dense(ds, activation=act, kernel_regularizer=regularizers.l2(0.01))(inp)\n",
    "    x = BN()(x)\n",
    "\n",
    "    x = Dense(ds // 2, activation=act, kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = BN()(x)\n",
    "\n",
    "    out = Dense(out_size, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inp, out, name='dnn_ge')\n",
    "    model.summary()\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.001 ,nesterov=False)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def model_scores(dnn, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "    \n",
    "    y_train_enc = keras.utils.to_categorical(y_train, 2)\n",
    "    y_test_enc = keras.utils.to_categorical(y_test, 2)\n",
    "    \n",
    "    dnn.fit(X_train, y_train_enc, epochs=epochs, batch_size=batch_size, class_weight=class_weights)\n",
    "    \n",
    "    y_pred_prob = dnn.predict(X_test)  \n",
    "    y_pred_class = y_pred_prob.argmax(axis=-1)\n",
    "    print(confusion_matrix(y_test,y_pred_class))\n",
    "    \n",
    "    train_scores = dnn.evaluate(X_train, y_train_enc)\n",
    "    test_scores = dnn.evaluate(X_test, y_test_enc)\n",
    "    \n",
    "    print(train_scores)\n",
    "    print(test_scores)\n",
    "\n",
    "    return(train_scores, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "act = \"tanh\"\n",
    "ds = 128\n",
    "int_size = 1000\n",
    "out_size = 2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_ge\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               128128    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 137,282\n",
      "Trainable params: 136,898\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 1s 480us/step - loss: 4.1580 - accuracy: 0.4832\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 0s 103us/step - loss: 4.0155 - accuracy: 0.5229\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 0s 114us/step - loss: 3.9186 - accuracy: 0.5450\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 0s 117us/step - loss: 3.8491 - accuracy: 0.5732\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 0s 111us/step - loss: 3.7991 - accuracy: 0.5917\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 0s 110us/step - loss: 3.7527 - accuracy: 0.6270\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 0s 101us/step - loss: 3.7098 - accuracy: 0.6561\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 0s 102us/step - loss: 3.6768 - accuracy: 0.6623\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 0s 102us/step - loss: 3.6426 - accuracy: 0.7028\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 0s 111us/step - loss: 3.6199 - accuracy: 0.7266\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 0s 111us/step - loss: 3.5830 - accuracy: 0.7513\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 0s 108us/step - loss: 3.5626 - accuracy: 0.7619\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 0s 110us/step - loss: 3.5333 - accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 0s 105us/step - loss: 3.5111 - accuracy: 0.7954\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 0s 111us/step - loss: 3.4972 - accuracy: 0.8131\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 0s 102us/step - loss: 3.4813 - accuracy: 0.8157\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 0s 99us/step - loss: 3.4636 - accuracy: 0.8307\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 0s 106us/step - loss: 3.4428 - accuracy: 0.8395\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 0s 116us/step - loss: 3.4266 - accuracy: 0.8474\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 0s 94us/step - loss: 3.4085 - accuracy: 0.8624\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 0s 89us/step - loss: 3.3979 - accuracy: 0.8704\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 0s 88us/step - loss: 3.3779 - accuracy: 0.8871\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 0s 90us/step - loss: 3.3619 - accuracy: 0.8862\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 0s 133us/step - loss: 3.3510 - accuracy: 0.9039\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 0s 112us/step - loss: 3.3434 - accuracy: 0.8898\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 0s 96us/step - loss: 3.3327 - accuracy: 0.8942\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 0s 90us/step - loss: 3.3176 - accuracy: 0.9083\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 0s 88us/step - loss: 3.3060 - accuracy: 0.9048\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 3.2904 - accuracy: 0.9162\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 0s 90us/step - loss: 3.2828 - accuracy: 0.9233\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 0s 96us/step - loss: 3.2744 - accuracy: 0.9083\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 0s 99us/step - loss: 3.2619 - accuracy: 0.9224\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 0s 105us/step - loss: 3.2555 - accuracy: 0.9242\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 0s 117us/step - loss: 3.2444 - accuracy: 0.9277\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 0s 118us/step - loss: 3.2384 - accuracy: 0.9198\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 0s 113us/step - loss: 3.2280 - accuracy: 0.9233\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 0s 121us/step - loss: 3.2172 - accuracy: 0.9312\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 0s 118us/step - loss: 3.2044 - accuracy: 0.9409\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 0s 131us/step - loss: 3.2038 - accuracy: 0.9250\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 0s 122us/step - loss: 3.1918 - accuracy: 0.9356\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 0s 110us/step - loss: 3.1854 - accuracy: 0.9339\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 0s 120us/step - loss: 3.1761 - accuracy: 0.9365\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 0s 110us/step - loss: 3.1645 - accuracy: 0.9462\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 0s 118us/step - loss: 3.1667 - accuracy: 0.9295\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 0s 124us/step - loss: 3.1556 - accuracy: 0.9356\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 0s 119us/step - loss: 3.1473 - accuracy: 0.9365\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 0s 118us/step - loss: 3.1398 - accuracy: 0.9365\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 0s 89us/step - loss: 3.1274 - accuracy: 0.9409\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 0s 103us/step - loss: 3.1249 - accuracy: 0.9427\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 0s 129us/step - loss: 3.1196 - accuracy: 0.9400\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 0s 119us/step - loss: 3.1110 - accuracy: 0.9418\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 0s 121us/step - loss: 3.1027 - accuracy: 0.9436\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 0s 110us/step - loss: 3.0955 - accuracy: 0.9436\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 0s 127us/step - loss: 3.0880 - accuracy: 0.9489\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 0s 112us/step - loss: 3.0845 - accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 0s 114us/step - loss: 3.0707 - accuracy: 0.9559\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 0s 111us/step - loss: 3.0724 - accuracy: 0.9453\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 0s 108us/step - loss: 3.0595 - accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 0s 115us/step - loss: 3.0581 - accuracy: 0.9489\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 0s 122us/step - loss: 3.0473 - accuracy: 0.9559\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 0s 107us/step - loss: 3.0427 - accuracy: 0.9541\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 0s 107us/step - loss: 3.0347 - accuracy: 0.9594\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 0s 106us/step - loss: 3.0320 - accuracy: 0.9568\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 0s 131us/step - loss: 3.0197 - accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 0s 114us/step - loss: 3.0189 - accuracy: 0.9533\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 0s 111us/step - loss: 3.0140 - accuracy: 0.9524\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 0s 113us/step - loss: 3.0054 - accuracy: 0.9541\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 0s 128us/step - loss: 3.0034 - accuracy: 0.9497\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 0s 125us/step - loss: 2.9953 - accuracy: 0.9559\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 0s 134us/step - loss: 2.9897 - accuracy: 0.9515\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 0s 109us/step - loss: 2.9841 - accuracy: 0.9559\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 0s 103us/step - loss: 2.9793 - accuracy: 0.9612\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 0s 98us/step - loss: 2.9699 - accuracy: 0.9612\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 0s 95us/step - loss: 2.9664 - accuracy: 0.9612\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 0s 107us/step - loss: 2.9585 - accuracy: 0.9577\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 0s 104us/step - loss: 2.9596 - accuracy: 0.9550\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.9486 - accuracy: 0.9630\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 0s 94us/step - loss: 2.9455 - accuracy: 0.9621\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 0s 89us/step - loss: 2.9348 - accuracy: 0.9691\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.9286 - accuracy: 0.9656\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 0s 98us/step - loss: 2.9283 - accuracy: 0.9568\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 2.9184 - accuracy: 0.9718\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.9144 - accuracy: 0.9683\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.9067 - accuracy: 0.9709\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 2.9056 - accuracy: 0.9683\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 0s 88us/step - loss: 2.8971 - accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 0s 89us/step - loss: 2.8887 - accuracy: 0.9744\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 0s 87us/step - loss: 2.8877 - accuracy: 0.9674\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 0s 89us/step - loss: 2.8845 - accuracy: 0.9700\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 0s 90us/step - loss: 2.8751 - accuracy: 0.9762\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 0s 88us/step - loss: 2.8732 - accuracy: 0.9674\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 2.8677 - accuracy: 0.9691\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.8621 - accuracy: 0.9718\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.8565 - accuracy: 0.9718\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 2.8510 - accuracy: 0.9727\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 0s 89us/step - loss: 2.8447 - accuracy: 0.9718\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 2.8442 - accuracy: 0.9691\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 0s 91us/step - loss: 2.8393 - accuracy: 0.9700\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 0s 92us/step - loss: 2.8322 - accuracy: 0.9744\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 0s 90us/step - loss: 2.8295 - accuracy: 0.9718\n",
      "[[505  10]\n",
      " [ 31  14]]\n",
      "1134/1134 [==============================] - 0s 109us/step\n",
      "560/560 [==============================] - 0s 49us/step\n",
      "[2.8105951705306924, 0.9814814925193787]\n",
      "[2.9194519179207936, 0.9267857074737549]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.8105951705306924, 0.9814814925193787],\n",
       " [2.9194519179207936, 0.9267857074737549])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_predicted_prob = random_forest.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc_curve(y_test, rf_predicted_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_predicted_prob = svm.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc_curve(y_test, svm_predicted_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnn_predicted_prob = dnn.predict(X_test)\n",
    "skplt.metrics.plot_roc_curve(y_test, dnn_predicted_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with oversampling train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ros_tr, y_train_ros_tr = RandomOverSampler(sampling_strategy = 'minority', random_state=42).fit_resample(X_train, y_train)\n",
    "X_train_sm_tr, y_train_sm_tr  = SMOTE(sampling_strategy = 'minority', random_state=42).fit_resample(X_train, y_train)\n",
    "X_train_ad_tr, y_train_ad_tr = ADASYN(sampling_strategy = 'minority', random_state=42).fit_resample(X_train, y_train)\n",
    "X_train_bls_tr, y_train_bls_tr  = BorderlineSMOTE(sampling_strategy = 'minority', random_state=42).fit_resample(X_train, y_train)\n",
    "X_train_svms_tr, y_train_svms_tr  = SVMSMOTE(sampling_strategy = 'minority', random_state=42).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1344/2064 [==================>...........] - ETA: 0s - loss: 3.3315 - accuracy: 0.6414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2059    1\n",
      "2060    1\n",
      "2061    1\n",
      "2062    1\n",
      "2063    1\n",
      "Name: Histological_Type, Length: 2064, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s 116us/step - loss: 3.2590 - accuracy: 0.6890\n",
      "Epoch 2/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 3.1365 - accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 3.0543 - accuracy: 0.8280\n",
      "Epoch 4/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.9966 - accuracy: 0.8517\n",
      "Epoch 5/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.9511 - accuracy: 0.8842\n",
      "Epoch 6/100\n",
      "2064/2064 [==============================] - 0s 105us/step - loss: 2.9060 - accuracy: 0.9031\n",
      "Epoch 7/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.8800 - accuracy: 0.9172\n",
      "Epoch 8/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 2.8470 - accuracy: 0.9293\n",
      "Epoch 9/100\n",
      "2064/2064 [==============================] - 0s 109us/step - loss: 2.8287 - accuracy: 0.9375\n",
      "Epoch 10/100\n",
      "2064/2064 [==============================] - 0s 132us/step - loss: 2.8149 - accuracy: 0.9438\n",
      "Epoch 11/100\n",
      "2064/2064 [==============================] - 0s 128us/step - loss: 2.7888 - accuracy: 0.9496\n",
      "Epoch 12/100\n",
      "2064/2064 [==============================] - 0s 118us/step - loss: 2.7732 - accuracy: 0.9549\n",
      "Epoch 13/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.7564 - accuracy: 0.9627\n",
      "Epoch 14/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 2.7333 - accuracy: 0.9719\n",
      "Epoch 15/100\n",
      "2064/2064 [==============================] - 0s 136us/step - loss: 2.7267 - accuracy: 0.9690\n",
      "Epoch 16/100\n",
      "2064/2064 [==============================] - 0s 120us/step - loss: 2.7075 - accuracy: 0.9787\n",
      "Epoch 17/100\n",
      "2064/2064 [==============================] - 0s 109us/step - loss: 2.6916 - accuracy: 0.9792\n",
      "Epoch 18/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.6824 - accuracy: 0.9787\n",
      "Epoch 19/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.6719 - accuracy: 0.9801\n",
      "Epoch 20/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.6685 - accuracy: 0.9821\n",
      "Epoch 21/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 2.6563 - accuracy: 0.9787\n",
      "Epoch 22/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.6437 - accuracy: 0.9835\n",
      "Epoch 23/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 2.6421 - accuracy: 0.9767\n",
      "Epoch 24/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.6251 - accuracy: 0.9879\n",
      "Epoch 25/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 2.6114 - accuracy: 0.9879\n",
      "Epoch 26/100\n",
      "2064/2064 [==============================] - 0s 110us/step - loss: 2.6030 - accuracy: 0.9869\n",
      "Epoch 27/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.6072 - accuracy: 0.9816\n",
      "Epoch 28/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 2.5901 - accuracy: 0.9898\n",
      "Epoch 29/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 2.5829 - accuracy: 0.9893\n",
      "Epoch 30/100\n",
      "2064/2064 [==============================] - 0s 110us/step - loss: 2.5802 - accuracy: 0.9840\n",
      "Epoch 31/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 2.5760 - accuracy: 0.9850\n",
      "Epoch 32/100\n",
      "2064/2064 [==============================] - 0s 110us/step - loss: 2.5632 - accuracy: 0.9893\n",
      "Epoch 33/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 2.5481 - accuracy: 0.9889\n",
      "Epoch 34/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.5374 - accuracy: 0.9932\n",
      "Epoch 35/100\n",
      "2064/2064 [==============================] - 0s 118us/step - loss: 2.5342 - accuracy: 0.9884\n",
      "Epoch 36/100\n",
      "2064/2064 [==============================] - 0s 109us/step - loss: 2.5325 - accuracy: 0.9889\n",
      "Epoch 37/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.5180 - accuracy: 0.9913\n",
      "Epoch 38/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 2.5020 - accuracy: 0.9913\n",
      "Epoch 39/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.4987 - accuracy: 0.9908\n",
      "Epoch 40/100\n",
      "2064/2064 [==============================] - 0s 110us/step - loss: 2.4916 - accuracy: 0.9908\n",
      "Epoch 41/100\n",
      "2064/2064 [==============================] - 0s 105us/step - loss: 2.4958 - accuracy: 0.9918\n",
      "Epoch 42/100\n",
      "2064/2064 [==============================] - 0s 108us/step - loss: 2.4799 - accuracy: 0.9922\n",
      "Epoch 43/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.4728 - accuracy: 0.9908\n",
      "Epoch 44/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 2.4705 - accuracy: 0.9908\n",
      "Epoch 45/100\n",
      "2064/2064 [==============================] - 0s 109us/step - loss: 2.4576 - accuracy: 0.9913\n",
      "Epoch 46/100\n",
      "2064/2064 [==============================] - 0s 104us/step - loss: 2.4496 - accuracy: 0.9947\n",
      "Epoch 47/100\n",
      "2064/2064 [==============================] - 0s 110us/step - loss: 2.4414 - accuracy: 0.9927\n",
      "Epoch 48/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 2.4390 - accuracy: 0.9898\n",
      "Epoch 49/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.4329 - accuracy: 0.9918\n",
      "Epoch 50/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 2.4174 - accuracy: 0.9932\n",
      "Epoch 51/100\n",
      "2064/2064 [==============================] - 0s 123us/step - loss: 2.4099 - accuracy: 0.9956\n",
      "Epoch 52/100\n",
      "2064/2064 [==============================] - 0s 123us/step - loss: 2.4111 - accuracy: 0.9922\n",
      "Epoch 53/100\n",
      "2064/2064 [==============================] - 0s 128us/step - loss: 2.4028 - accuracy: 0.9947\n",
      "Epoch 54/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.3949 - accuracy: 0.9922\n",
      "Epoch 55/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.3876 - accuracy: 0.9932\n",
      "Epoch 56/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 2.3839 - accuracy: 0.9932\n",
      "Epoch 57/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 2.3818 - accuracy: 0.9927\n",
      "Epoch 58/100\n",
      "2064/2064 [==============================] - 0s 103us/step - loss: 2.3696 - accuracy: 0.9952\n",
      "Epoch 59/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.3630 - accuracy: 0.9918\n",
      "Epoch 60/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 2.3524 - accuracy: 0.9952\n",
      "Epoch 61/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 2.3445 - accuracy: 0.9966\n",
      "Epoch 62/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.3420 - accuracy: 0.9952\n",
      "Epoch 63/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.3369 - accuracy: 0.9913\n",
      "Epoch 64/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 2.3239 - accuracy: 0.9976\n",
      "Epoch 65/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.3220 - accuracy: 0.9952\n",
      "Epoch 66/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 2.3174 - accuracy: 0.9942\n",
      "Epoch 67/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 2.3107 - accuracy: 0.9961\n",
      "Epoch 68/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 2.3069 - accuracy: 0.9942\n",
      "Epoch 69/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 2.2942 - accuracy: 0.9956\n",
      "Epoch 70/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 2.2928 - accuracy: 0.9947\n",
      "Epoch 71/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 2.2762 - accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 2.2744 - accuracy: 0.9956\n",
      "Epoch 73/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 2.2687 - accuracy: 0.9966\n",
      "Epoch 74/100\n",
      "2064/2064 [==============================] - 0s 90us/step - loss: 2.2614 - accuracy: 0.9961\n",
      "Epoch 75/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 2.2627 - accuracy: 0.9971\n",
      "Epoch 76/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 2.2562 - accuracy: 0.9952\n",
      "Epoch 77/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 2.2450 - accuracy: 0.9956\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s 98us/step - loss: 2.2367 - accuracy: 0.9976\n",
      "Epoch 79/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.2358 - accuracy: 0.9971\n",
      "Epoch 80/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.2322 - accuracy: 0.9952\n",
      "Epoch 81/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.2232 - accuracy: 0.9976\n",
      "Epoch 82/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 2.2118 - accuracy: 0.9976\n",
      "Epoch 83/100\n",
      "2064/2064 [==============================] - 0s 90us/step - loss: 2.2058 - accuracy: 0.9976\n",
      "Epoch 84/100\n",
      "2064/2064 [==============================] - 0s 92us/step - loss: 2.2034 - accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 2.2009 - accuracy: 0.9952\n",
      "Epoch 86/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.1875 - accuracy: 0.9981\n",
      "Epoch 87/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.1904 - accuracy: 0.9956\n",
      "Epoch 88/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 2.1858 - accuracy: 0.9966\n",
      "Epoch 89/100\n",
      "2064/2064 [==============================] - 0s 119us/step - loss: 2.1725 - accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "2064/2064 [==============================] - 0s 91us/step - loss: 2.1699 - accuracy: 0.9966\n",
      "Epoch 91/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 2.1651 - accuracy: 0.9956\n",
      "Epoch 92/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 2.1619 - accuracy: 0.9971\n",
      "Epoch 93/100\n",
      "2064/2064 [==============================] - 0s 86us/step - loss: 2.1499 - accuracy: 0.9971\n",
      "Epoch 94/100\n",
      "2064/2064 [==============================] - 0s 86us/step - loss: 2.1429 - accuracy: 0.9976\n",
      "Epoch 95/100\n",
      "2064/2064 [==============================] - 0s 87us/step - loss: 2.1359 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 2.1320 - accuracy: 0.9966\n",
      "Epoch 97/100\n",
      "2064/2064 [==============================] - 0s 92us/step - loss: 2.1271 - accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 2.1254 - accuracy: 0.9971\n",
      "Epoch 99/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 2.1173 - accuracy: 0.9961\n",
      "Epoch 100/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 2.1149 - accuracy: 0.9971\n",
      "[[484  31]\n",
      " [ 23  22]]\n",
      "2064/2064 [==============================] - 0s 40us/step\n",
      "560/560 [==============================] - 0s 50us/step\n",
      "[2.0980720649393954, 1.0]\n",
      "[2.450188820702689, 0.9035714268684387]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.0980720649393954, 1.0], [2.450188820702689, 0.9035714268684387])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn, X_train_ros_tr, y_train_ros_tr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.1061 - accuracy: 0.9966\n",
      "Epoch 2/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 2.0973 - accuracy: 0.9985\n",
      "Epoch 3/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 2.0899 - accuracy: 0.9981\n",
      "Epoch 4/100\n",
      "2064/2064 [==============================] - 0s 104us/step - loss: 2.0896 - accuracy: 0.9976\n",
      "Epoch 5/100\n",
      "2064/2064 [==============================] - 0s 109us/step - loss: 2.0798 - accuracy: 0.9981\n",
      "Epoch 6/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.0790 - accuracy: 0.9966\n",
      "Epoch 7/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.0720 - accuracy: 0.9971\n",
      "Epoch 8/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.0705 - accuracy: 0.9961\n",
      "Epoch 9/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 2.0589 - accuracy: 0.9985\n",
      "Epoch 10/100\n",
      "2064/2064 [==============================] - 0s 109us/step - loss: 2.0545 - accuracy: 0.9971\n",
      "Epoch 11/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.0479 - accuracy: 0.9976\n",
      "Epoch 12/100\n",
      "2064/2064 [==============================] - 0s 103us/step - loss: 2.0401 - accuracy: 0.9995\n",
      "Epoch 13/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 2.0392 - accuracy: 0.9966\n",
      "Epoch 14/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 2.0340 - accuracy: 0.9971\n",
      "Epoch 15/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 2.0249 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 2.0238 - accuracy: 0.9971\n",
      "Epoch 17/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 2.0171 - accuracy: 0.9990\n",
      "Epoch 18/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 2.0116 - accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 2.0048 - accuracy: 0.9981\n",
      "Epoch 20/100\n",
      "2064/2064 [==============================] - 0s 118us/step - loss: 1.9959 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.9943 - accuracy: 0.9990\n",
      "Epoch 22/100\n",
      "2064/2064 [==============================] - 0s 118us/step - loss: 1.9868 - accuracy: 0.9990\n",
      "Epoch 23/100\n",
      "2064/2064 [==============================] - 0s 127us/step - loss: 1.9852 - accuracy: 0.9995\n",
      "Epoch 24/100\n",
      "2064/2064 [==============================] - 0s 127us/step - loss: 1.9764 - accuracy: 0.9990\n",
      "Epoch 25/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 1.9747 - accuracy: 0.9981\n",
      "Epoch 26/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.9745 - accuracy: 0.9956\n",
      "Epoch 27/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 1.9647 - accuracy: 0.9985\n",
      "Epoch 28/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.9584 - accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "2064/2064 [==============================] - 0s 105us/step - loss: 1.9505 - accuracy: 0.9981\n",
      "Epoch 30/100\n",
      "2064/2064 [==============================] - 0s 91us/step - loss: 1.9488 - accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 1.9462 - accuracy: 0.9971\n",
      "Epoch 32/100\n",
      "2064/2064 [==============================] - 0s 119us/step - loss: 1.9373 - accuracy: 0.9995\n",
      "Epoch 33/100\n",
      "2064/2064 [==============================] - 0s 122us/step - loss: 1.9294 - accuracy: 0.9990\n",
      "Epoch 34/100\n",
      "2064/2064 [==============================] - 0s 101us/step - loss: 1.9282 - accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 1.9220 - accuracy: 0.9985\n",
      "Epoch 36/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 1.9169 - accuracy: 0.9990\n",
      "Epoch 37/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 1.9146 - accuracy: 0.9981\n",
      "Epoch 38/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.9061 - accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 1.9043 - accuracy: 0.9981\n",
      "Epoch 40/100\n",
      "2064/2064 [==============================] - 0s 121us/step - loss: 1.8980 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "2064/2064 [==============================] - 0s 118us/step - loss: 1.8902 - accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "2064/2064 [==============================] - 0s 121us/step - loss: 1.8883 - accuracy: 0.9990\n",
      "Epoch 43/100\n",
      "2064/2064 [==============================] - 0s 122us/step - loss: 1.8838 - accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "2064/2064 [==============================] - 0s 123us/step - loss: 1.8768 - accuracy: 0.9995\n",
      "Epoch 45/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 1.8760 - accuracy: 0.9971\n",
      "Epoch 46/100\n",
      "2064/2064 [==============================] - 0s 117us/step - loss: 1.8665 - accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.8624 - accuracy: 0.9985\n",
      "Epoch 48/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 1.8579 - accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "2064/2064 [==============================] - 0s 103us/step - loss: 1.8548 - accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "2064/2064 [==============================] - 0s 103us/step - loss: 1.8449 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.8446 - accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.8446 - accuracy: 0.9966\n",
      "Epoch 53/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 1.8315 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.8278 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.8272 - accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 1.8187 - accuracy: 0.9995\n",
      "Epoch 57/100\n",
      "2064/2064 [==============================] - 0s 119us/step - loss: 1.8152 - accuracy: 0.9990\n",
      "Epoch 58/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.8097 - accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "2064/2064 [==============================] - 0s 117us/step - loss: 1.8034 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.8072 - accuracy: 0.9971\n",
      "Epoch 61/100\n",
      "2064/2064 [==============================] - 0s 117us/step - loss: 1.7938 - accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 1.7923 - accuracy: 0.9990\n",
      "Epoch 63/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 1.7902 - accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "2064/2064 [==============================] - 0s 111us/step - loss: 1.7823 - accuracy: 0.9981\n",
      "Epoch 65/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 1.7757 - accuracy: 0.9995\n",
      "Epoch 66/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.7708 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.7694 - accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 1.7637 - accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "2064/2064 [==============================] - 0s 102us/step - loss: 1.7644 - accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.7558 - accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.7480 - accuracy: 0.9995\n",
      "Epoch 72/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.7455 - accuracy: 0.9990\n",
      "Epoch 73/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 1.7385 - accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.7353 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.7298 - accuracy: 0.9995\n",
      "Epoch 76/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.7263 - accuracy: 0.9995\n",
      "Epoch 77/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 1.7200 - accuracy: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.7187 - accuracy: 0.9985\n",
      "Epoch 79/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.7126 - accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "2064/2064 [==============================] - 0s 92us/step - loss: 1.7079 - accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 1.7037 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 1.6985 - accuracy: 1.0000 0s - loss: 1.7006 - accuracy: 1.\n",
      "Epoch 83/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 1.6938 - accuracy: 0.9995\n",
      "Epoch 84/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.6918 - accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.6880 - accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 1.6840 - accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 1.6758 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 1.6728 - accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 1.6658 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 1.6655 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2064/2064 [==============================] - 0s 92us/step - loss: 1.6584 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2064/2064 [==============================] - 0s 91us/step - loss: 1.6558 - accuracy: 0.9985\n",
      "Epoch 93/100\n",
      "2064/2064 [==============================] - 0s 89us/step - loss: 1.6516 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2064/2064 [==============================] - 0s 89us/step - loss: 1.6481 - accuracy: 0.9995\n",
      "Epoch 95/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 1.6423 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "2064/2064 [==============================] - 0s 89us/step - loss: 1.6410 - accuracy: 0.9985\n",
      "Epoch 97/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 1.6336 - accuracy: 0.9995\n",
      "Epoch 98/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.6322 - accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.6277 - accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.6258 - accuracy: 0.9971\n",
      "[[476  39]\n",
      " [ 23  22]]\n",
      "2064/2064 [==============================] - 0s 36us/step\n",
      "560/560 [==============================] - 0s 55us/step\n",
      "[1.614447643590528, 1.0]\n",
      "[2.0632729257856095, 0.8892857432365417]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.614447643590528, 1.0], [2.0632729257856095, 0.8892857432365417])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn, X_train_sm_tr, y_train_sm_tr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1472/2061 [====================>.........] - ETA: 0s - loss: 1.6200 - accuracy: 0.9993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2056    1\n",
      "2057    1\n",
      "2058    1\n",
      "2059    1\n",
      "2060    1\n",
      "Name: Histological_Type, Length: 2061, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061/2061 [==============================] - 0s 108us/step - loss: 1.6189 - accuracy: 0.9995\n",
      "Epoch 2/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.6161 - accuracy: 0.9985\n",
      "Epoch 3/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.6091 - accuracy: 0.9995\n",
      "Epoch 4/100\n",
      "2061/2061 [==============================] - 0s 106us/step - loss: 1.6071 - accuracy: 0.9995\n",
      "Epoch 5/100\n",
      "2061/2061 [==============================] - 0s 95us/step - loss: 1.6013 - accuracy: 0.9990\n",
      "Epoch 6/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.5972 - accuracy: 0.9990\n",
      "Epoch 7/100\n",
      "2061/2061 [==============================] - 0s 127us/step - loss: 1.5915 - accuracy: 0.9995\n",
      "Epoch 8/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.5900 - accuracy: 0.9976\n",
      "Epoch 9/100\n",
      "2061/2061 [==============================] - 0s 96us/step - loss: 1.5814 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "2061/2061 [==============================] - 0s 104us/step - loss: 1.5789 - accuracy: 0.9995\n",
      "Epoch 11/100\n",
      "2061/2061 [==============================] - 0s 113us/step - loss: 1.5769 - accuracy: 0.9995\n",
      "Epoch 12/100\n",
      "2061/2061 [==============================] - 0s 112us/step - loss: 1.5713 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "2061/2061 [==============================] - 0s 109us/step - loss: 1.5647 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "2061/2061 [==============================] - 0s 110us/step - loss: 1.5696 - accuracy: 0.9961\n",
      "Epoch 15/100\n",
      "2061/2061 [==============================] - 0s 117us/step - loss: 1.5606 - accuracy: 0.9995\n",
      "Epoch 16/100\n",
      "2061/2061 [==============================] - 0s 119us/step - loss: 1.5540 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "2061/2061 [==============================] - 0s 110us/step - loss: 1.5490 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "2061/2061 [==============================] - 0s 107us/step - loss: 1.5477 - accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.5432 - accuracy: 0.9990\n",
      "Epoch 20/100\n",
      "2061/2061 [==============================] - 0s 92us/step - loss: 1.5385 - accuracy: 0.9995\n",
      "Epoch 21/100\n",
      "2061/2061 [==============================] - 0s 102us/step - loss: 1.5348 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "2061/2061 [==============================] - 0s 92us/step - loss: 1.5353 - accuracy: 0.9995\n",
      "Epoch 23/100\n",
      "2061/2061 [==============================] - 0s 92us/step - loss: 1.5293 - accuracy: 0.9990\n",
      "Epoch 24/100\n",
      "2061/2061 [==============================] - 0s 96us/step - loss: 1.5208 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "2061/2061 [==============================] - 0s 98us/step - loss: 1.5203 - accuracy: 0.9995\n",
      "Epoch 26/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.5139 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "2061/2061 [==============================] - 0s 92us/step - loss: 1.5093 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "2061/2061 [==============================] - 0s 110us/step - loss: 1.5072 - accuracy: 0.9995\n",
      "Epoch 29/100\n",
      "2061/2061 [==============================] - 0s 90us/step - loss: 1.5020 - accuracy: 0.9995\n",
      "Epoch 30/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.5005 - accuracy: 0.9990\n",
      "Epoch 31/100\n",
      "2061/2061 [==============================] - 0s 102us/step - loss: 1.4975 - accuracy: 0.9981\n",
      "Epoch 32/100\n",
      "2061/2061 [==============================] - 0s 109us/step - loss: 1.4933 - accuracy: 0.9985\n",
      "Epoch 33/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.4916 - accuracy: 0.9966\n",
      "Epoch 34/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.4854 - accuracy: 0.9995\n",
      "Epoch 35/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.4819 - accuracy: 0.9990\n",
      "Epoch 36/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.4738 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "2061/2061 [==============================] - 0s 89us/step - loss: 1.4719 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "2061/2061 [==============================] - 0s 100us/step - loss: 1.4693 - accuracy: 0.9990\n",
      "Epoch 39/100\n",
      "2061/2061 [==============================] - 0s 100us/step - loss: 1.4645 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.4601 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.4588 - accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "2061/2061 [==============================] - 0s 89us/step - loss: 1.4535 - accuracy: 0.9990\n",
      "Epoch 43/100\n",
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.4495 - accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "2061/2061 [==============================] - 0s 105us/step - loss: 1.4453 - accuracy: 0.9995\n",
      "Epoch 45/100\n",
      "2061/2061 [==============================] - 0s 104us/step - loss: 1.4415 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "2061/2061 [==============================] - 0s 86us/step - loss: 1.4402 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.4354 - accuracy: 0.9995\n",
      "Epoch 48/100\n",
      "2061/2061 [==============================] - 0s 89us/step - loss: 1.4340 - accuracy: 0.9985\n",
      "Epoch 49/100\n",
      "2061/2061 [==============================] - 0s 104us/step - loss: 1.4304 - accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "2061/2061 [==============================] - 0s 101us/step - loss: 1.4246 - accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "2061/2061 [==============================] - 0s 106us/step - loss: 1.4190 - accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "2061/2061 [==============================] - 0s 113us/step - loss: 1.4184 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "2061/2061 [==============================] - 0s 115us/step - loss: 1.4111 - accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "2061/2061 [==============================] - 0s 111us/step - loss: 1.4072 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2061/2061 [==============================] - 0s 110us/step - loss: 1.4057 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2061/2061 [==============================] - 0s 121us/step - loss: 1.4010 - accuracy: 0.9995\n",
      "Epoch 57/100\n",
      "2061/2061 [==============================] - 0s 101us/step - loss: 1.3971 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2061/2061 [==============================] - 0s 108us/step - loss: 1.3947 - accuracy: 0.9995\n",
      "Epoch 59/100\n",
      "2061/2061 [==============================] - 0s 109us/step - loss: 1.3900 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2061/2061 [==============================] - 0s 102us/step - loss: 1.3876 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2061/2061 [==============================] - 0s 103us/step - loss: 1.3854 - accuracy: 0.9990\n",
      "Epoch 62/100\n",
      "2061/2061 [==============================] - 0s 95us/step - loss: 1.3792 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "2061/2061 [==============================] - 0s 90us/step - loss: 1.3763 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.3728 - accuracy: 0.9995\n",
      "Epoch 65/100\n",
      "2061/2061 [==============================] - 0s 104us/step - loss: 1.3670 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.3671 - accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.3630 - accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "2061/2061 [==============================] - 0s 98us/step - loss: 1.3582 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.3559 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2061/2061 [==============================] - 0s 90us/step - loss: 1.3503 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.3465 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.3419 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.3409 - accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "2061/2061 [==============================] - 0s 101us/step - loss: 1.3368 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.3343 - accuracy: 0.9990\n",
      "Epoch 76/100\n",
      "2061/2061 [==============================] - 0s 96us/step - loss: 1.3293 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.3274 - accuracy: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.3250 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2061/2061 [==============================] - 0s 90us/step - loss: 1.3220 - accuracy: 0.9990\n",
      "Epoch 80/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.3159 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2061/2061 [==============================] - 0s 94us/step - loss: 1.3124 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2061/2061 [==============================] - 0s 90us/step - loss: 1.3108 - accuracy: 0.9995\n",
      "Epoch 83/100\n",
      "2061/2061 [==============================] - 0s 88us/step - loss: 1.3089 - accuracy: 0.9981\n",
      "Epoch 84/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.3029 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2061/2061 [==============================] - 0s 89us/step - loss: 1.3019 - accuracy: 0.9995\n",
      "Epoch 86/100\n",
      "2061/2061 [==============================] - 0s 91us/step - loss: 1.2951 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2061/2061 [==============================] - 0s 94us/step - loss: 1.2927 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2061/2061 [==============================] - 0s 98us/step - loss: 1.2879 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2061/2061 [==============================] - 0s 94us/step - loss: 1.2864 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.2821 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2061/2061 [==============================] - 0s 95us/step - loss: 1.2789 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2061/2061 [==============================] - 0s 96us/step - loss: 1.2774 - accuracy: 0.9990\n",
      "Epoch 93/100\n",
      "2061/2061 [==============================] - 0s 95us/step - loss: 1.2736 - accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "2061/2061 [==============================] - 0s 96us/step - loss: 1.2689 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.2690 - accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "2061/2061 [==============================] - 0s 94us/step - loss: 1.2627 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "2061/2061 [==============================] - 0s 99us/step - loss: 1.2589 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2061/2061 [==============================] - 0s 93us/step - loss: 1.2551 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "2061/2061 [==============================] - 0s 96us/step - loss: 1.2519 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2061/2061 [==============================] - 0s 97us/step - loss: 1.2494 - accuracy: 1.0000\n",
      "[[451  64]\n",
      " [ 19  26]]\n",
      "2061/2061 [==============================] - 0s 44us/step\n",
      "560/560 [==============================] - 0s 52us/step\n",
      "[1.2484834501316453, 1.0]\n",
      "[1.8426572016307285, 0.8517857193946838]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.2484834501316453, 1.0], [1.8426572016307285, 0.8517857193946838])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn, X_train_ad_tr, y_train_ad_tr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2064/2064 [==============================] - 0s 110us/step - loss: 1.2485 - accuracy: 0.9985\n",
      "Epoch 2/100\n",
      "2064/2064 [==============================] - 0s 153us/step - loss: 1.2434 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.2407 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 1.2370 - accuracy: 0.9995\n",
      "Epoch 5/100\n",
      "2064/2064 [==============================] - 0s 117us/step - loss: 1.2347 - accuracy: 0.9990\n",
      "Epoch 6/100\n",
      "2064/2064 [==============================] - 0s 126us/step - loss: 1.2306 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "2064/2064 [==============================] - 0s 139us/step - loss: 1.2263 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.2220 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "2064/2064 [==============================] - 0s 117us/step - loss: 1.2259 - accuracy: 0.9985\n",
      "Epoch 10/100\n",
      "2064/2064 [==============================] - 0s 122us/step - loss: 1.2173 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "2064/2064 [==============================] - 0s 102us/step - loss: 1.2143 - accuracy: 0.9995\n",
      "Epoch 12/100\n",
      "2064/2064 [==============================] - 0s 101us/step - loss: 1.2124 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 1.2070 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "2064/2064 [==============================] - 0s 107us/step - loss: 1.2032 - accuracy: 0.9995\n",
      "Epoch 15/100\n",
      "2064/2064 [==============================] - 0s 166us/step - loss: 1.2011 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "2064/2064 [==============================] - 0s 116us/step - loss: 1.1965 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.1955 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.1921 - accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 1.1905 - accuracy: 0.9995\n",
      "Epoch 20/100\n",
      "2064/2064 [==============================] - 0s 130us/step - loss: 1.1850 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 1.1821 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "2064/2064 [==============================] - 0s 129us/step - loss: 1.1811 - accuracy: 0.9995\n",
      "Epoch 23/100\n",
      "2064/2064 [==============================] - 0s 119us/step - loss: 1.1764 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.1771 - accuracy: 0.9990\n",
      "Epoch 25/100\n",
      "2064/2064 [==============================] - 0s 108us/step - loss: 1.1711 - accuracy: 0.9990\n",
      "Epoch 26/100\n",
      "2064/2064 [==============================] - 0s 105us/step - loss: 1.1672 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 1.1640 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "2064/2064 [==============================] - 0s 127us/step - loss: 1.1600 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "2064/2064 [==============================] - 0s 122us/step - loss: 1.1589 - accuracy: 0.9995\n",
      "Epoch 30/100\n",
      "2064/2064 [==============================] - 0s 113us/step - loss: 1.1547 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 1.1525 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "2064/2064 [==============================] - 0s 102us/step - loss: 1.1498 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "2064/2064 [==============================] - 0s 104us/step - loss: 1.1458 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "2064/2064 [==============================] - 0s 122us/step - loss: 1.1443 - accuracy: 0.9995\n",
      "Epoch 35/100\n",
      "2064/2064 [==============================] - 0s 114us/step - loss: 1.1401 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 1.1409 - accuracy: 0.9981\n",
      "Epoch 37/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.1332 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.1355 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.1280 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "2064/2064 [==============================] - 0s 101us/step - loss: 1.1270 - accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.1239 - accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 1.1232 - accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "2064/2064 [==============================] - 0s 105us/step - loss: 1.1192 - accuracy: 0.9985\n",
      "Epoch 44/100\n",
      "2064/2064 [==============================] - 0s 108us/step - loss: 1.1139 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 1.1104 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "2064/2064 [==============================] - 0s 101us/step - loss: 1.1077 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 1.1049 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 1.1043 - accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "2064/2064 [==============================] - 0s 101us/step - loss: 1.1077 - accuracy: 0.9971\n",
      "Epoch 50/100\n",
      "2064/2064 [==============================] - 0s 101us/step - loss: 1.0962 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.0938 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.0924 - accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.0888 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.0850 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2064/2064 [==============================] - 0s 100us/step - loss: 1.0835 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2064/2064 [==============================] - 0s 118us/step - loss: 1.0793 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 1.0769 - accuracy: 0.9995\n",
      "Epoch 58/100\n",
      "2064/2064 [==============================] - 0s 213us/step - loss: 1.0756 - accuracy: 0.9995\n",
      "Epoch 59/100\n",
      "2064/2064 [==============================] - 0s 115us/step - loss: 1.0719 - accuracy: 0.9990\n",
      "Epoch 60/100\n",
      "2064/2064 [==============================] - 0s 112us/step - loss: 1.0679 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2064/2064 [==============================] - 0s 106us/step - loss: 1.0659 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.0646 - accuracy: 0.9995\n",
      "Epoch 63/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.0594 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.0574 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.0550 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.0520 - accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.0498 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.0459 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2064/2064 [==============================] - 0s 102us/step - loss: 1.0436 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.0421 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2064/2064 [==============================] - 0s 97us/step - loss: 1.0381 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2064/2064 [==============================] - 0s 98us/step - loss: 1.0367 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2064/2064 [==============================] - 0s 99us/step - loss: 1.0331 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "2064/2064 [==============================] - 0s 96us/step - loss: 1.0307 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2064/2064 [==============================] - 0s 92us/step - loss: 1.0293 - accuracy: 0.9995\n",
      "Epoch 76/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 1.0249 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2064/2064 [==============================] - 0s 104us/step - loss: 1.0226 - accuracy: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s 94us/step - loss: 1.0189 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 1.0181 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 1.0150 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 1.0131 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2064/2064 [==============================] - 0s 87us/step - loss: 1.0094 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2064/2064 [==============================] - 0s 87us/step - loss: 1.0096 - accuracy: 0.9985\n",
      "Epoch 84/100\n",
      "2064/2064 [==============================] - 0s 87us/step - loss: 1.0039 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 1.0006 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2064/2064 [==============================] - 0s 90us/step - loss: 0.9978 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 0.9984 - accuracy: 0.9990\n",
      "Epoch 88/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 0.9939 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2064/2064 [==============================] - 0s 90us/step - loss: 0.9915 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2064/2064 [==============================] - 0s 90us/step - loss: 0.9886 - accuracy: 0.9995\n",
      "Epoch 91/100\n",
      "2064/2064 [==============================] - 0s 89us/step - loss: 0.9855 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2064/2064 [==============================] - 0s 90us/step - loss: 0.9836 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2064/2064 [==============================] - 0s 89us/step - loss: 0.9810 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2064/2064 [==============================] - 0s 88us/step - loss: 0.9788 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2064/2064 [==============================] - 0s 87us/step - loss: 0.9764 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "2064/2064 [==============================] - 0s 89us/step - loss: 0.9758 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 0.9695 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2064/2064 [==============================] - 0s 94us/step - loss: 0.9712 - accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "2064/2064 [==============================] - 0s 93us/step - loss: 0.9655 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2064/2064 [==============================] - 0s 95us/step - loss: 0.9677 - accuracy: 0.9981\n",
      "[[494  21]\n",
      " [ 28  17]]\n",
      "2064/2064 [==============================] - 0s 39us/step\n",
      "560/560 [==============================] - 0s 41us/step\n",
      "[0.9616749138795129, 1.0]\n",
      "[1.4744514908109392, 0.9125000238418579]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.9616749138795129, 1.0], [1.4744514908109392, 0.9125000238418579])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn, X_train_bls_tr, y_train_bls_tr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 0.9794 - accuracy: 0.9951\n",
      "Epoch 2/100\n",
      "  32/1646 [..............................] - ETA: 0s - loss: 0.9578 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1641    1\n",
      "1642    1\n",
      "1643    1\n",
      "1644    1\n",
      "1645    1\n",
      "Name: Histological_Type, Length: 1646, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 105us/step - loss: 0.9767 - accuracy: 0.9921\n",
      "Epoch 3/100\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 0.9681 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.9661 - accuracy: 0.9957\n",
      "Epoch 5/100\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 0.9689 - accuracy: 0.9970\n",
      "Epoch 6/100\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 0.9657 - accuracy: 0.9945\n",
      "Epoch 7/100\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 0.9624 - accuracy: 0.9957\n",
      "Epoch 8/100\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 0.9558 - accuracy: 0.9982\n",
      "Epoch 9/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.9527 - accuracy: 0.9994\n",
      "Epoch 10/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.9531 - accuracy: 0.9976\n",
      "Epoch 11/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.9569 - accuracy: 0.9957\n",
      "Epoch 12/100\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 0.9472 - accuracy: 0.9994\n",
      "Epoch 13/100\n",
      "1646/1646 [==============================] - 0s 106us/step - loss: 0.9495 - accuracy: 0.9970\n",
      "Epoch 14/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.9462 - accuracy: 0.9964\n",
      "Epoch 15/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.9432 - accuracy: 0.9982\n",
      "Epoch 16/100\n",
      "1646/1646 [==============================] - 0s 104us/step - loss: 0.9471 - accuracy: 0.9939\n",
      "Epoch 17/100\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 0.9390 - accuracy: 0.9988\n",
      "Epoch 18/100\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 0.9361 - accuracy: 0.9988\n",
      "Epoch 19/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.9368 - accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 0.9317 - accuracy: 0.9988\n",
      "Epoch 21/100\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 0.9298 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.9276 - accuracy: 0.9988\n",
      "Epoch 23/100\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 0.9239 - accuracy: 0.9994\n",
      "Epoch 24/100\n",
      "1646/1646 [==============================] - 0s 104us/step - loss: 0.9240 - accuracy: 0.9988\n",
      "Epoch 25/100\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 0.9209 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 0.9197 - accuracy: 0.9982\n",
      "Epoch 27/100\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 0.9178 - accuracy: 0.9982\n",
      "Epoch 28/100\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 0.9188 - accuracy: 0.9970\n",
      "Epoch 29/100\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 0.9159 - accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 0.9127 - accuracy: 0.9988\n",
      "Epoch 31/100\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 0.9158 - accuracy: 0.9945\n",
      "Epoch 32/100\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 0.9051 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.9050 - accuracy: 0.9994\n",
      "Epoch 34/100\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 0.9038 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 0.9014 - accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 0.9071 - accuracy: 0.9964\n",
      "Epoch 37/100\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 0.8989 - accuracy: 0.9994\n",
      "Epoch 38/100\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 0.8975 - accuracy: 0.9994\n",
      "Epoch 39/100\n",
      "1646/1646 [==============================] - 0s 104us/step - loss: 0.8925 - accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 0.8922 - accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 0.8885 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 0.8872 - accuracy: 0.9994\n",
      "Epoch 43/100\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 0.8837 - accuracy: 0.9994\n",
      "Epoch 44/100\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 0.8845 - accuracy: 0.9988\n",
      "Epoch 45/100\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 0.8818 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 0.8788 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 0.8780 - accuracy: 0.9994\n",
      "Epoch 48/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.8841 - accuracy: 0.9976\n",
      "Epoch 49/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.8780 - accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 0.8733 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 0.8743 - accuracy: 0.9988\n",
      "Epoch 52/100\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 0.8699 - accuracy: 0.9994\n",
      "Epoch 53/100\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 0.8685 - accuracy: 0.9994\n",
      "Epoch 54/100\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 0.8661 - accuracy: 0.9994\n",
      "Epoch 55/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.8622 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.8615 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 0.8594 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1646/1646 [==============================] - 0s 115us/step - loss: 0.8586 - accuracy: 0.9994\n",
      "Epoch 59/100\n",
      "1646/1646 [==============================] - 0s 112us/step - loss: 0.8570 - accuracy: 0.9982\n",
      "Epoch 60/100\n",
      "1646/1646 [==============================] - 0s 114us/step - loss: 0.8548 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1646/1646 [==============================] - 0s 116us/step - loss: 0.8572 - accuracy: 0.9988\n",
      "Epoch 62/100\n",
      "1646/1646 [==============================] - 0s 116us/step - loss: 0.8551 - accuracy: 0.9994\n",
      "Epoch 63/100\n",
      "1646/1646 [==============================] - 0s 115us/step - loss: 0.8527 - accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "1646/1646 [==============================] - 0s 122us/step - loss: 0.8465 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 0.8454 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.8425 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 0.8421 - accuracy: 0.9994\n",
      "Epoch 68/100\n",
      "1646/1646 [==============================] - 0s 119us/step - loss: 0.8393 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1646/1646 [==============================] - 0s 111us/step - loss: 0.8390 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 0.8368 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 0.8361 - accuracy: 0.9994\n",
      "Epoch 72/100\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 0.8380 - accuracy: 0.9988\n",
      "Epoch 73/100\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 0.8336 - accuracy: 0.9982\n",
      "Epoch 74/100\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 0.8298 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 0.8329 - accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "1646/1646 [==============================] - 0s 104us/step - loss: 0.8275 - accuracy: 0.9994\n",
      "Epoch 77/100\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 0.8251 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 0.8240 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 94us/step - loss: 0.8216 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 0.8196 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 0.8185 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 0.8180 - accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 0.8167 - accuracy: 0.9982\n",
      "Epoch 84/100\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 0.8123 - accuracy: 0.9994\n",
      "Epoch 85/100\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 0.8120 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 0.8102 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 0.8089 - accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 0.8063 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 0.8053 - accuracy: 0.9994\n",
      "Epoch 90/100\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 0.8017 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 0.8018 - accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "1646/1646 [==============================] - 0s 114us/step - loss: 0.7994 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 0.7996 - accuracy: 0.9994\n",
      "Epoch 94/100\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 0.7975 - accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "1646/1646 [==============================] - 0s 117us/step - loss: 0.7959 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1646/1646 [==============================] - 0s 114us/step - loss: 0.7939 - accuracy: 0.9994\n",
      "Epoch 97/100\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 0.7909 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 0.7880 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 0.7868 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 0.7860 - accuracy: 1.0000\n",
      "[[471  44]\n",
      " [ 22  23]]\n",
      "1646/1646 [==============================] - 0s 41us/step\n",
      "560/560 [==============================] - 0s 46us/step\n",
      "[0.7810357785166976, 1.0]\n",
      "[1.2798235075814384, 0.8821428418159485]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7810357785166976, 1.0], [1.2798235075814384, 0.8821428418159485])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn, X_train_svms_tr, y_train_svms_tr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hist with the whole gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_all_genes = pd.read_csv(\"all_genes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_all_genes_hist = pd.concat([MB_all_genes, raw_data['Histological_Type']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_all_genes_hist_IDC_ILC = MB_all_genes_hist[(MB_all_genes_hist['Histological_Type'] == 'IDC') | (MB_all_genes_hist['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1694, 24369)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_all_genes_hist_IDC_ILC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TMPRSS7',\n",
       " 'SLC25A19',\n",
       " 'IDO1',\n",
       " 'CSNK2A1',\n",
       " 'BAMBI',\n",
       " 'MRPL24',\n",
       " 'AK127905',\n",
       " 'FAM71A']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols = [i for i in MB_all_genes_hist_IDC_ILC.columns if MB_all_genes_hist_IDC_ILC[i].isnull().any()]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "# MB_all_genes_hist_IDC_ILC.replace([np.inf, -np.inf, np.nan], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_type = MB_all_genes_hist_IDC_ILC.iloc[:,-1]\n",
    "hist_type .replace({\"IDC\":0,\"ILC\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_all_genes_hist_IDC_ILC = MB_all_genes_hist_IDC_ILC.drop([\"Histological_Type\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_all_genes_hist_IDC_ILC = MB_all_genes_hist_IDC_ILC.drop(\n",
    "    ['TMPRSS7',\n",
    " 'SLC25A19',\n",
    " 'IDO1',\n",
    " 'CSNK2A1',\n",
    " 'BAMBI',\n",
    " 'MRPL24',\n",
    " 'AK127905',\n",
    " 'FAM71A'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1694, 24360)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_all_genes_hist_IDC_ILC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(MB_all_genes_hist_IDC_ILC, hist_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_all():\n",
    "    reset_random_seeds()\n",
    "    \n",
    "    inp = Input(shape=(int_size,))\n",
    "\n",
    "    x = Dense(ds, activation=act, kernel_regularizer=regularizers.l2(0.01))(inp)\n",
    "    x = BN()(x)\n",
    "\n",
    "    x = Dense(ds//4, activation=act, kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = BN()(x)\n",
    "\n",
    "    out = Dense(out_size, activation='softmax')(x)\n",
    "\n",
    "    dnn_all = Model(inp, out, name='dnn_ge')\n",
    "    dnn_all.summary()\n",
    "\n",
    "#     sgd = optimizers.SGD(lr=0.0001 ,nesterov=False)\n",
    "    adam = optimizers.Adam(learning_rate=0.00005, clipvalue=1)\n",
    "    dnn_all.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return dnn_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "act = \"tanh\"\n",
    "ds = 256\n",
    "int_size = 24360\n",
    "out_size = 2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_ge\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 24360)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               6236416   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,254,274\n",
      "Trainable params: 6,253,634\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_all = build_model_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 7.0748 - accuracy: 0.5018\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 6.6722 - accuracy: 0.6376\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 6.4835 - accuracy: 0.7337\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 6.3284 - accuracy: 0.8272\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 6.1895 - accuracy: 0.8959\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 6.0600 - accuracy: 0.9153\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 5.9267 - accuracy: 0.9295\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 5.8058 - accuracy: 0.9101\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 5.6824 - accuracy: 0.9012\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 5.5607 - accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 5.4387 - accuracy: 0.9074\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 5.3040 - accuracy: 0.9356\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 5.1835 - accuracy: 0.9286\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 5.0693 - accuracy: 0.9224\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.9572 - accuracy: 0.9295\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.8637 - accuracy: 0.9021\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.7673 - accuracy: 0.8951\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.6341 - accuracy: 0.9374\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 4.5219 - accuracy: 0.9383\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.3986 - accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.2928 - accuracy: 0.9700\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.1992 - accuracy: 0.9603\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.0929 - accuracy: 0.9735\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 4.0054 - accuracy: 0.9665\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.9084 - accuracy: 0.9621\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.8108 - accuracy: 0.9753\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.7321 - accuracy: 0.9586\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.6375 - accuracy: 0.9674\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.5502 - accuracy: 0.9700\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.4837 - accuracy: 0.9524\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.4153 - accuracy: 0.9541\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.3300 - accuracy: 0.9515\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.2540 - accuracy: 0.9621\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.1647 - accuracy: 0.9709\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.0889 - accuracy: 0.9735\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 3.0247 - accuracy: 0.9594\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.9512 - accuracy: 0.9762\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.8892 - accuracy: 0.9727\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.8353 - accuracy: 0.9612\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.7563 - accuracy: 0.9727\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6829 - accuracy: 0.9859\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6391 - accuracy: 0.9674\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.5701 - accuracy: 0.9780\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.5212 - accuracy: 0.9780\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.4512 - accuracy: 0.9850\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.4244 - accuracy: 0.9568\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.4265 - accuracy: 0.9268\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.3220 - accuracy: 0.9683\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.2827 - accuracy: 0.9638\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.2164 - accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.1652 - accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.1091 - accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0621 - accuracy: 0.9868\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.0314 - accuracy: 0.9700\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.9967 - accuracy: 0.9727\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.9310 - accuracy: 0.9929\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9045 - accuracy: 0.9744\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.8790 - accuracy: 0.9762\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8252 - accuracy: 0.9885\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7822 - accuracy: 0.9832\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7587 - accuracy: 0.9700\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7195 - accuracy: 0.9806\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.6853 - accuracy: 0.9850\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.6352 - accuracy: 0.9929\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.6171 - accuracy: 0.9841\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.5772 - accuracy: 0.9921\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.5346 - accuracy: 0.9956\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.5182 - accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.4802 - accuracy: 0.9894\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4729 - accuracy: 0.9797\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4479 - accuracy: 0.9797\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.4272 - accuracy: 0.9753\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.4233 - accuracy: 0.9665\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.3849 - accuracy: 0.9797\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.3414 - accuracy: 0.9912\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3355 - accuracy: 0.9753\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.3021 - accuracy: 0.9877\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.2694 - accuracy: 0.9903\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.2616 - accuracy: 0.9788\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.2376 - accuracy: 0.9841\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 1.2029 - accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.1798 - accuracy: 0.9929\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 1.1765 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.1326 - accuracy: 0.9965\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1190 - accuracy: 0.9921\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1026 - accuracy: 0.9921\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.0819 - accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.0567 - accuracy: 0.9965\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.0665 - accuracy: 0.9780\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.0602 - accuracy: 0.9797\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.0377 - accuracy: 0.9806\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.0263 - accuracy: 0.9841\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.0089 - accuracy: 0.9877\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.9688 - accuracy: 0.9956\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.9476 - accuracy: 0.9965\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.9226 - accuracy: 0.9991\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 0.9017 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.9028 - accuracy: 0.9912\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.9236 - accuracy: 0.9753\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 0.9311 - accuracy: 0.9683\n",
      "[[474  41]\n",
      " [ 39   6]]\n",
      "1134/1134 [==============================] - 1s 1ms/step\n",
      "560/560 [==============================] - 0s 805us/step\n",
      "[0.847852956996393, 1.0]\n",
      "[1.230682625089373, 0.8571428656578064]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.847852956996393, 1.0], [1.230682625089373, 0.8571428656578064])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn_all ,X_train_all, y_train_all, X_test_all, y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting with oversampling train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_bls_tr, y_train_all_bls_tr  = BorderlineSMOTE(sampling_strategy = 'minority', random_state=42).fit_resample(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\r",
      "  64/2064 [..............................] - ETA: 5s - loss: 0.8226 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2059    1\n",
      "2060    1\n",
      "2061    1\n",
      "2062    1\n",
      "2063    1\n",
      "Name: Histological_Type, Length: 2064, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.8137 - accuracy: 0.9985\n",
      "Epoch 2/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.7893 - accuracy: 0.9995\n",
      "Epoch 3/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.7698 - accuracy: 0.9990\n",
      "Epoch 4/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.7444 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.7220 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.7007 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.6801 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.6603 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.6410 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.6225 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.6043 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5868 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5698 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5534 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5375 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5220 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5070 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4924 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4782 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4646 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4512 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4384 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4257 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4134 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.4015 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3899 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3786 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3676 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3569 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3465 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3363 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3265 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3169 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3075 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2984 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2895 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2808 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2724 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2641 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2561 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2483 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2407 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2333 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2260 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2190 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2121 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.2054 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.2468 - accuracy: 0.9840\n",
      "Epoch 49/100\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.3021 - accuracy: 0.9748\n",
      "Epoch 50/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2467 - accuracy: 0.9981\n",
      "Epoch 51/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2318 - accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "2064/2064 [==============================] - 5s 3ms/step - loss: 0.2203 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.2111 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.2021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1941 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1871 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1818 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1742 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1680 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1619 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1563 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1510 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1458 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1409 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.1363 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1319 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1276 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1233 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1151 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1112 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2064/2064 [==============================] - 5s 3ms/step - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2064/2064 [==============================] - 5s 3ms/step - loss: 0.1039 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1006 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.0973 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0939 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0906 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "2064/2064 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0843 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0813 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0756 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0728 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0702 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0579 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0557 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0535 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0473 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2064/2064 [==============================] - 4s 2ms/step - loss: 0.3021 - accuracy: 0.9273\n",
      "Epoch 98/100\n",
      "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1993 - accuracy: 0.9855\n",
      "Epoch 99/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1388 - accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1233 - accuracy: 0.9995\n",
      "[[500  15]\n",
      " [ 43   2]]\n",
      "2064/2064 [==============================] - 2s 1ms/step\n",
      "560/560 [==============================] - 0s 850us/step\n",
      "[0.12034752346979555, 1.0]\n",
      "[0.5842969076974052, 0.8964285850524902]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.12034752346979555, 1.0], [0.5842969076974052, 0.8964285850524902])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn_all, X_train_all_bls_tr, y_train_all_bls_tr, X_test_all, y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hist with Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalar-k50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k50 = pd.read_csv(\"scalar_measures_k50_all_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scalar_k50.catalog_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2233, 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k50.rename(columns={\"catalog_ID\": \"METABRIC_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k50_raw_data_hist = pd.merge(scalar_k50, raw_data, on='METABRIC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k50_raw_data_hist_IDC_ILC = scalar_k50_raw_data_hist[(scalar_k50_raw_data_hist['Histological_Type'] == 'IDC') | (scalar_k50_raw_data_hist['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1888, 2047)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k50_raw_data_hist_IDC_ILC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k50_hist_IDC_ILC= scalar_k50_raw_data_hist_IDC_ILC.iloc[:, 2:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "scalar_k50_hist_type = scalar_k50_raw_data_hist_IDC_ILC['Histological_Type']\n",
    "scalar_k50_hist_type.replace({\"IDC\":0,\"ILC\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sk50, X_test_sk50, y_train_sk50, y_test_sk50 = train_test_split(scalar_k50_hist_IDC_ILC, scalar_k50_hist_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9038461538461539\n",
      "[[563   1]\n",
      " [ 59   1]]\n"
     ]
    }
   ],
   "source": [
    "random_forest = random_forest.fit(X_train_sk50, y_train_sk50)\n",
    "predicted_rf = random_forest.predict(X_test_sk50)\n",
    "print(accuracy_score(y_test_sk50,predicted_rf))\n",
    "print(confusion_matrix(y_test_sk50, predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_ge\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 227\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model_images():\n",
    "    reset_random_seeds()\n",
    "    \n",
    "    inp = Input(shape=(int_size,))\n",
    "\n",
    "    x = Dense(ds, activation=act)(inp)\n",
    "    x = BN()(x)\n",
    "\n",
    "    x = Dense(ds // 2, activation=act)(x)\n",
    "    x = BN()(x)\n",
    "\n",
    "    out = Dense(out_size, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inp, out, name='dnn_ge')\n",
    "    model.summary()\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.01 ,nesterov=False)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "act = \"tanh\"\n",
    "ds = 10\n",
    "int_size = 12\n",
    "out_size = 2\n",
    "epochs = 100\n",
    "\n",
    "dnn_sk50 = build_model_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=1755    0\n",
      "988     1\n",
      "210     0\n",
      "1317    0\n",
      "1313    0\n",
      "       ..\n",
      "1421    0\n",
      "1593    0\n",
      "1073    0\n",
      "1762    1\n",
      "1416    0\n",
      "Name: Histological_Type, Length: 1264, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 0s 286us/step - loss: 0.8394 - accuracy: 0.6076\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.5295 - accuracy: 0.7603\n",
      "Epoch 3/100\n",
      "1264/1264 [==============================] - 0s 71us/step - loss: 0.4315 - accuracy: 0.8750\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3955 - accuracy: 0.8861\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3757 - accuracy: 0.8916\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3642 - accuracy: 0.8932\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.3550 - accuracy: 0.8932\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 0s 65us/step - loss: 0.3517 - accuracy: 0.8932\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3506 - accuracy: 0.8932\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3445 - accuracy: 0.8932\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3478 - accuracy: 0.8932\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3443 - accuracy: 0.8932\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3454 - accuracy: 0.8932\n",
      "Epoch 14/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3456 - accuracy: 0.8932\n",
      "Epoch 15/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3424 - accuracy: 0.8932\n",
      "Epoch 16/100\n",
      "1264/1264 [==============================] - 0s 64us/step - loss: 0.3441 - accuracy: 0.8932\n",
      "Epoch 17/100\n",
      "1264/1264 [==============================] - 0s 71us/step - loss: 0.3434 - accuracy: 0.8932\n",
      "Epoch 18/100\n",
      "1264/1264 [==============================] - 0s 71us/step - loss: 0.3416 - accuracy: 0.8932\n",
      "Epoch 19/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3444 - accuracy: 0.8932\n",
      "Epoch 20/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3400 - accuracy: 0.8932\n",
      "Epoch 21/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3420 - accuracy: 0.8932\n",
      "Epoch 22/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.3405 - accuracy: 0.8932\n",
      "Epoch 23/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3444 - accuracy: 0.8932\n",
      "Epoch 24/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.3407 - accuracy: 0.8932\n",
      "Epoch 25/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3445 - accuracy: 0.8932\n",
      "Epoch 26/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.3405 - accuracy: 0.8932\n",
      "Epoch 27/100\n",
      "1264/1264 [==============================] - 0s 70us/step - loss: 0.3410 - accuracy: 0.8932\n",
      "Epoch 28/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.3400 - accuracy: 0.8932\n",
      "Epoch 29/100\n",
      "1264/1264 [==============================] - 0s 72us/step - loss: 0.3387 - accuracy: 0.8932\n",
      "Epoch 30/100\n",
      "1264/1264 [==============================] - 0s 62us/step - loss: 0.3404 - accuracy: 0.8932\n",
      "Epoch 31/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.3410 - accuracy: 0.8932\n",
      "Epoch 32/100\n",
      "1264/1264 [==============================] - 0s 68us/step - loss: 0.3434 - accuracy: 0.8932\n",
      "Epoch 33/100\n",
      "1264/1264 [==============================] - 0s 62us/step - loss: 0.3434 - accuracy: 0.8932\n",
      "Epoch 34/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.3392 - accuracy: 0.8932\n",
      "Epoch 35/100\n",
      "1264/1264 [==============================] - 0s 69us/step - loss: 0.3411 - accuracy: 0.8932\n",
      "Epoch 36/100\n",
      "1264/1264 [==============================] - 0s 67us/step - loss: 0.3417 - accuracy: 0.8932\n",
      "Epoch 37/100\n",
      "1264/1264 [==============================] - 0s 62us/step - loss: 0.3419 - accuracy: 0.8932\n",
      "Epoch 38/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.3402 - accuracy: 0.8932\n",
      "Epoch 39/100\n",
      "1264/1264 [==============================] - 0s 65us/step - loss: 0.3402 - accuracy: 0.8932\n",
      "Epoch 40/100\n",
      "1264/1264 [==============================] - 0s 71us/step - loss: 0.3397 - accuracy: 0.8932\n",
      "Epoch 41/100\n",
      "1264/1264 [==============================] - 0s 69us/step - loss: 0.3393 - accuracy: 0.8932\n",
      "Epoch 42/100\n",
      "1264/1264 [==============================] - 0s 66us/step - loss: 0.3405 - accuracy: 0.8932\n",
      "Epoch 43/100\n",
      "1264/1264 [==============================] - 0s 73us/step - loss: 0.3410 - accuracy: 0.8932\n",
      "Epoch 44/100\n",
      "1264/1264 [==============================] - 0s 70us/step - loss: 0.3400 - accuracy: 0.8932\n",
      "Epoch 45/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.3401 - accuracy: 0.8932\n",
      "Epoch 46/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.3359 - accuracy: 0.8932\n",
      "Epoch 47/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3397 - accuracy: 0.8932\n",
      "Epoch 48/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.3412 - accuracy: 0.8932\n",
      "Epoch 49/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3397 - accuracy: 0.8932\n",
      "Epoch 50/100\n",
      "1264/1264 [==============================] - 0s 77us/step - loss: 0.3388 - accuracy: 0.8932\n",
      "Epoch 51/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3415 - accuracy: 0.8932\n",
      "Epoch 52/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.3399 - accuracy: 0.8932\n",
      "Epoch 53/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3407 - accuracy: 0.8932\n",
      "Epoch 54/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3395 - accuracy: 0.8932\n",
      "Epoch 55/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3388 - accuracy: 0.8932\n",
      "Epoch 56/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3375 - accuracy: 0.8932\n",
      "Epoch 57/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3376 - accuracy: 0.8932\n",
      "Epoch 58/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3385 - accuracy: 0.8932\n",
      "Epoch 59/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.3401 - accuracy: 0.8932\n",
      "Epoch 60/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3397 - accuracy: 0.8932\n",
      "Epoch 61/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3381 - accuracy: 0.8932\n",
      "Epoch 62/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3397 - accuracy: 0.8932\n",
      "Epoch 63/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3407 - accuracy: 0.8932\n",
      "Epoch 64/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3399 - accuracy: 0.8932\n",
      "Epoch 65/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3391 - accuracy: 0.8932\n",
      "Epoch 66/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3393 - accuracy: 0.8932\n",
      "Epoch 67/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.3400 - accuracy: 0.8932\n",
      "Epoch 68/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.3381 - accuracy: 0.8932\n",
      "Epoch 69/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3382 - accuracy: 0.8932\n",
      "Epoch 70/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.3384 - accuracy: 0.8932\n",
      "Epoch 71/100\n",
      "1264/1264 [==============================] - 0s 64us/step - loss: 0.3363 - accuracy: 0.8932\n",
      "Epoch 72/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3376 - accuracy: 0.8932\n",
      "Epoch 73/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.3387 - accuracy: 0.8932\n",
      "Epoch 74/100\n",
      "1264/1264 [==============================] - 0s 70us/step - loss: 0.3372 - accuracy: 0.8932\n",
      "Epoch 75/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3382 - accuracy: 0.8932\n",
      "Epoch 76/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3400 - accuracy: 0.8932\n",
      "Epoch 77/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3395 - accuracy: 0.8932\n",
      "Epoch 78/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3408 - accuracy: 0.8932\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.3374 - accuracy: 0.8932\n",
      "Epoch 80/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3402 - accuracy: 0.8932\n",
      "Epoch 81/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3413 - accuracy: 0.8932\n",
      "Epoch 82/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.3375 - accuracy: 0.8932\n",
      "Epoch 83/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3365 - accuracy: 0.8932\n",
      "Epoch 84/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.3397 - accuracy: 0.8932\n",
      "Epoch 85/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3377 - accuracy: 0.8932\n",
      "Epoch 86/100\n",
      "1264/1264 [==============================] - 0s 52us/step - loss: 0.3368 - accuracy: 0.8932\n",
      "Epoch 87/100\n",
      "1264/1264 [==============================] - 0s 52us/step - loss: 0.3378 - accuracy: 0.8932\n",
      "Epoch 88/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3362 - accuracy: 0.8932\n",
      "Epoch 89/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3367 - accuracy: 0.8932\n",
      "Epoch 90/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.3367 - accuracy: 0.8932\n",
      "Epoch 91/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3367 - accuracy: 0.8932\n",
      "Epoch 92/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.3361 - accuracy: 0.8932\n",
      "Epoch 93/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3381 - accuracy: 0.8932\n",
      "Epoch 94/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.3382 - accuracy: 0.8932\n",
      "Epoch 95/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3414 - accuracy: 0.8932\n",
      "Epoch 96/100\n",
      "1264/1264 [==============================] - 0s 52us/step - loss: 0.3388 - accuracy: 0.8932\n",
      "Epoch 97/100\n",
      "1264/1264 [==============================] - 0s 52us/step - loss: 0.3378 - accuracy: 0.8932\n",
      "Epoch 98/100\n",
      "1264/1264 [==============================] - 0s 53us/step - loss: 0.3371 - accuracy: 0.8932\n",
      "Epoch 99/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.3384 - accuracy: 0.8932\n",
      "Epoch 100/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.3390 - accuracy: 0.8932\n",
      "[[564   0]\n",
      " [ 60   0]]\n",
      "1264/1264 [==============================] - 0s 73us/step\n",
      "624/624 [==============================] - 0s 30us/step\n",
      "[0.3364875908893875, 0.8931962251663208]\n",
      "[0.31734931545379835, 0.9038461446762085]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.3364875908893875, 0.8931962251663208],\n",
       " [0.31734931545379835, 0.9038461446762085])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn_sk50, X_train_sk50, y_train_sk50, X_test_sk50, y_test_sk50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalar-k10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k10 = pd.read_csv(\"scalar_measures_k10_all_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2231, 14)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k10.rename(columns={\"catalog_ID\": \"METABRIC_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k10_raw_data_hist = pd.merge(scalar_k10, raw_data, on='METABRIC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k10_raw_data_hist_IDC_ILC = scalar_k10_raw_data_hist[(scalar_k10_raw_data_hist['Histological_Type'] == 'IDC') | (scalar_k10_raw_data_hist['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k10_hist_IDC_ILC= scalar_k10_raw_data_hist_IDC_ILC.iloc[:, 2:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_k10_hist_type = scalar_k10_raw_data_hist_IDC_ILC['Histological_Type']\n",
    "scalar_k10_hist_type.replace({\"IDC\":0,\"ILC\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sk10, X_test_sk10, y_train_sk10, y_test_sk10 = train_test_split(scalar_k10_hist_IDC_ILC, scalar_k10_hist_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701923076923077\n",
      "[[541   2]\n",
      " [ 79   2]]\n"
     ]
    }
   ],
   "source": [
    "random_forest = random_forest.fit(X_train_sk10, y_train_sk10)\n",
    "predicted_rf = random_forest.predict(X_test_sk10)\n",
    "print(accuracy_score(y_test_sk10,predicted_rf))\n",
    "print(confusion_matrix(y_test_sk10, predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_ge\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 227\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=1752    0\n",
      "985     1\n",
      "210     0\n",
      "1312    0\n",
      "1308    0\n",
      "       ..\n",
      "1417    0\n",
      "1589    0\n",
      "1070    0\n",
      "1758    0\n",
      "1412    0\n",
      "Name: Histological_Type, Length: 1266, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 0s 274us/step - loss: 0.8669 - accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.5180 - accuracy: 0.7709\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.4173 - accuracy: 0.8791\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3720 - accuracy: 0.9028\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 0s 59us/step - loss: 0.3455 - accuracy: 0.9076\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3342 - accuracy: 0.9068\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 0s 64us/step - loss: 0.3286 - accuracy: 0.9068\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3226 - accuracy: 0.9060\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3204 - accuracy: 0.9068\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3148 - accuracy: 0.9068\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3147 - accuracy: 0.9068\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3116 - accuracy: 0.9076\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3115 - accuracy: 0.9068\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3138 - accuracy: 0.9068\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 0s 70us/step - loss: 0.3122 - accuracy: 0.9068\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3142 - accuracy: 0.9068\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3091 - accuracy: 0.9068\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 0s 60us/step - loss: 0.3101 - accuracy: 0.9068\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 0s 58us/step - loss: 0.3090 - accuracy: 0.9068\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3145 - accuracy: 0.9068\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3108 - accuracy: 0.9068\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3103 - accuracy: 0.9068\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3107 - accuracy: 0.9068\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3129 - accuracy: 0.9068\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3087 - accuracy: 0.9068\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3108 - accuracy: 0.9068\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3106 - accuracy: 0.9068\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3130 - accuracy: 0.9068\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3091 - accuracy: 0.9068\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 0s 58us/step - loss: 0.3116 - accuracy: 0.9068\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 0s 60us/step - loss: 0.3062 - accuracy: 0.9068\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3138 - accuracy: 0.9068\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3112 - accuracy: 0.9068\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3088 - accuracy: 0.9068\n",
      "Epoch 35/100\n",
      "1266/1266 [==============================] - 0s 56us/step - loss: 0.3074 - accuracy: 0.9068\n",
      "Epoch 36/100\n",
      "1266/1266 [==============================] - 0s 56us/step - loss: 0.3105 - accuracy: 0.9068\n",
      "Epoch 37/100\n",
      "1266/1266 [==============================] - 0s 65us/step - loss: 0.3086 - accuracy: 0.9068\n",
      "Epoch 38/100\n",
      "1266/1266 [==============================] - 0s 70us/step - loss: 0.3088 - accuracy: 0.9068\n",
      "Epoch 39/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3080 - accuracy: 0.9068\n",
      "Epoch 40/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3094 - accuracy: 0.9068\n",
      "Epoch 41/100\n",
      "1266/1266 [==============================] - 0s 60us/step - loss: 0.3055 - accuracy: 0.9068\n",
      "Epoch 42/100\n",
      "1266/1266 [==============================] - 0s 65us/step - loss: 0.3073 - accuracy: 0.9068\n",
      "Epoch 43/100\n",
      "1266/1266 [==============================] - 0s 81us/step - loss: 0.3084 - accuracy: 0.9068\n",
      "Epoch 44/100\n",
      "1266/1266 [==============================] - 0s 64us/step - loss: 0.3086 - accuracy: 0.9068\n",
      "Epoch 45/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3080 - accuracy: 0.9068\n",
      "Epoch 46/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3072 - accuracy: 0.9068\n",
      "Epoch 47/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3091 - accuracy: 0.9068\n",
      "Epoch 48/100\n",
      "1266/1266 [==============================] - 0s 58us/step - loss: 0.3100 - accuracy: 0.9068\n",
      "Epoch 49/100\n",
      "1266/1266 [==============================] - 0s 61us/step - loss: 0.3087 - accuracy: 0.9068\n",
      "Epoch 50/100\n",
      "1266/1266 [==============================] - 0s 69us/step - loss: 0.3085 - accuracy: 0.9068\n",
      "Epoch 51/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3083 - accuracy: 0.9068\n",
      "Epoch 52/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3045 - accuracy: 0.9068\n",
      "Epoch 53/100\n",
      "1266/1266 [==============================] - 0s 51us/step - loss: 0.3054 - accuracy: 0.9068\n",
      "Epoch 54/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3049 - accuracy: 0.9068\n",
      "Epoch 55/100\n",
      "1266/1266 [==============================] - 0s 68us/step - loss: 0.3081 - accuracy: 0.9068\n",
      "Epoch 56/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3097 - accuracy: 0.9068\n",
      "Epoch 57/100\n",
      "1266/1266 [==============================] - 0s 65us/step - loss: 0.3053 - accuracy: 0.9068\n",
      "Epoch 58/100\n",
      "1266/1266 [==============================] - 0s 68us/step - loss: 0.3065 - accuracy: 0.9068\n",
      "Epoch 59/100\n",
      "1266/1266 [==============================] - 0s 56us/step - loss: 0.3070 - accuracy: 0.9068\n",
      "Epoch 60/100\n",
      "1266/1266 [==============================] - 0s 51us/step - loss: 0.3080 - accuracy: 0.9068\n",
      "Epoch 61/100\n",
      "1266/1266 [==============================] - 0s 51us/step - loss: 0.3070 - accuracy: 0.9068\n",
      "Epoch 62/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3077 - accuracy: 0.9068\n",
      "Epoch 63/100\n",
      "1266/1266 [==============================] - 0s 60us/step - loss: 0.3053 - accuracy: 0.9068\n",
      "Epoch 64/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3059 - accuracy: 0.9068\n",
      "Epoch 65/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3041 - accuracy: 0.9068\n",
      "Epoch 66/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3045 - accuracy: 0.9068\n",
      "Epoch 67/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3059 - accuracy: 0.9068\n",
      "Epoch 68/100\n",
      "1266/1266 [==============================] - 0s 61us/step - loss: 0.3054 - accuracy: 0.9068\n",
      "Epoch 69/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3049 - accuracy: 0.9068\n",
      "Epoch 70/100\n",
      "1266/1266 [==============================] - 0s 58us/step - loss: 0.3088 - accuracy: 0.9068\n",
      "Epoch 71/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3077 - accuracy: 0.9068\n",
      "Epoch 72/100\n",
      "1266/1266 [==============================] - 0s 55us/step - loss: 0.3072 - accuracy: 0.9068\n",
      "Epoch 73/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3083 - accuracy: 0.9068\n",
      "Epoch 74/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3077 - accuracy: 0.9068\n",
      "Epoch 75/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3087 - accuracy: 0.9068\n",
      "Epoch 76/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3108 - accuracy: 0.9068\n",
      "Epoch 77/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3054 - accuracy: 0.9068\n",
      "Epoch 78/100\n",
      "1266/1266 [==============================] - 0s 51us/step - loss: 0.3075 - accuracy: 0.9068\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266/1266 [==============================] - 0s 58us/step - loss: 0.3078 - accuracy: 0.9068\n",
      "Epoch 80/100\n",
      "1266/1266 [==============================] - 0s 69us/step - loss: 0.3070 - accuracy: 0.9068\n",
      "Epoch 81/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3084 - accuracy: 0.9068\n",
      "Epoch 82/100\n",
      "1266/1266 [==============================] - 0s 52us/step - loss: 0.3091 - accuracy: 0.9068\n",
      "Epoch 83/100\n",
      "1266/1266 [==============================] - 0s 67us/step - loss: 0.3072 - accuracy: 0.9068\n",
      "Epoch 84/100\n",
      "1266/1266 [==============================] - 0s 66us/step - loss: 0.3057 - accuracy: 0.9068\n",
      "Epoch 85/100\n",
      "1266/1266 [==============================] - 0s 73us/step - loss: 0.3068 - accuracy: 0.9068\n",
      "Epoch 86/100\n",
      "1266/1266 [==============================] - 0s 68us/step - loss: 0.3053 - accuracy: 0.9068\n",
      "Epoch 87/100\n",
      "1266/1266 [==============================] - 0s 71us/step - loss: 0.3049 - accuracy: 0.9068\n",
      "Epoch 88/100\n",
      "1266/1266 [==============================] - 0s 68us/step - loss: 0.3047 - accuracy: 0.9068\n",
      "Epoch 89/100\n",
      "1266/1266 [==============================] - 0s 62us/step - loss: 0.3051 - accuracy: 0.9068\n",
      "Epoch 90/100\n",
      "1266/1266 [==============================] - 0s 63us/step - loss: 0.3059 - accuracy: 0.9068\n",
      "Epoch 91/100\n",
      "1266/1266 [==============================] - 0s 61us/step - loss: 0.3068 - accuracy: 0.9068\n",
      "Epoch 92/100\n",
      "1266/1266 [==============================] - 0s 64us/step - loss: 0.3065 - accuracy: 0.9068\n",
      "Epoch 93/100\n",
      "1266/1266 [==============================] - 0s 59us/step - loss: 0.3062 - accuracy: 0.9068\n",
      "Epoch 94/100\n",
      "1266/1266 [==============================] - 0s 54us/step - loss: 0.3060 - accuracy: 0.9068\n",
      "Epoch 95/100\n",
      "1266/1266 [==============================] - 0s 58us/step - loss: 0.3065 - accuracy: 0.9068\n",
      "Epoch 96/100\n",
      "1266/1266 [==============================] - 0s 57us/step - loss: 0.3073 - accuracy: 0.9068\n",
      "Epoch 97/100\n",
      "1266/1266 [==============================] - 0s 59us/step - loss: 0.3067 - accuracy: 0.9068\n",
      "Epoch 98/100\n",
      "1266/1266 [==============================] - 0s 61us/step - loss: 0.3076 - accuracy: 0.9068\n",
      "Epoch 99/100\n",
      "1266/1266 [==============================] - 0s 59us/step - loss: 0.3095 - accuracy: 0.9068\n",
      "Epoch 100/100\n",
      "1266/1266 [==============================] - 0s 53us/step - loss: 0.3062 - accuracy: 0.9068\n",
      "[[543   0]\n",
      " [ 81   0]]\n",
      "1266/1266 [==============================] - 0s 83us/step\n",
      "624/624 [==============================] - 0s 35us/step\n",
      "[0.3050723954399615, 0.9067930579185486]\n",
      "[0.40058133693841785, 0.870192289352417]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.3050723954399615, 0.9067930579185486],\n",
       " [0.40058133693841785, 0.870192289352417])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_sk10 = build_model_images()\n",
    "model_scores(dnn_sk10, X_train_sk10, y_train_sk10, X_test_sk10, y_test_sk10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vector_k10 pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10 = pd.read_csv(\"vector_measures_k10_all_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10.rename(columns={\"catalog_ID\": \"METABRIC_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10.iloc[:,2:370] = scaler.fit_transform(vector_k10.iloc[:,2:370])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_raw_data_hist = pd.merge(vector_k10, raw_data, on='METABRIC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_raw_data_hist_IDC_ILC = vector_k10_raw_data_hist[(vector_k10_raw_data_hist['Histological_Type'] == 'IDC') | (vector_k10_raw_data_hist['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "vector_k10_raw_data_hist_IDC_ILC['Histological_Type'].replace({\"IDC\":0,\"ILC\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_ge\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 368)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                11808     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 12,562\n",
      "Trainable params: 12,466\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_size = 368\n",
    "ds = 32\n",
    "dnn_vk10 = build_model_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(skf, X, y, model):\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        train_score, test_score = model_scores(model, X_train, y_train, X_test, y_test)\n",
    "        train_scores.append(train_score[1])\n",
    "        test_scores.append(test_score[1])\n",
    "    print(np.mean(train_scores))\n",
    "    print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector-k10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_hist_IDC_ILC= vector_k10_raw_data_hist_IDC_ILC.iloc[:, 2:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_hist_type = vector_k10_raw_data_hist_IDC_ILC['Histological_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vk10, X_test_vk10, y_train_vk10, y_test_vk10 = train_test_split(vector_k10_hist_IDC_ILC, vector_k10_hist_type, test_size=0.33, random_state=42)\n",
    "X = vector_k10_hist_IDC_ILC\n",
    "y = vector_k10_hist_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([   0,    1,    2,    3,    5,    6,    7,    8,    9,   13,\\n            ...\\n            1878, 1879, 1880, 1881, 1882, 1885, 1886, 1887, 1888, 1889],\\n           dtype='int64', length=1512)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-51e3c5c9be70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdnn_vk10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-241-f43c1536c366>\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m(skf, X, y, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([   0,    1,    2,    3,    5,    6,    7,    8,    9,   13,\\n            ...\\n            1878, 1879, 1880, 1881, 1882, 1885, 1886, 1887, 1888, 1889],\\n           dtype='int64', length=1512)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "cross_val(skf, X, y,dnn_vk10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector-k10 No Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_raw_data_hist_IDC_ILC_ND = vector_k10_raw_data_hist_IDC_ILC.drop_duplicates(subset=['METABRIC_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241, 2403)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_k10_raw_data_hist_IDC_ILC_ND.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_hist_IDC_ILC_ND = vector_k10_raw_data_hist_IDC_ILC_ND.iloc[:, 2:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k10_hist_type_ND = vector_k10_raw_data_hist_IDC_ILC_ND['Histological_Type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vk10_ND, X_test_vk10_ND, y_train_vk10_ND, y_test_vk10_ND = train_test_split(vector_k10_hist_IDC_ILC_ND, vector_k10_hist_type_ND, test_size=0.33, random_state=42)\n",
    "X = vector_k10_hist_IDC_ILC_ND\n",
    "y = vector_k10_hist_type_ND.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "831/831 [==============================] - 0s 109us/step - loss: 0.1651 - accuracy: 0.9362\n",
      "Epoch 2/100\n",
      "831/831 [==============================] - 0s 76us/step - loss: 0.1541 - accuracy: 0.9495\n",
      "Epoch 3/100\n",
      " 32/831 [>.............................] - ETA: 0s - loss: 0.0647 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=976     0\n",
      "71      0\n",
      "1075    0\n",
      "1417    0\n",
      "115     0\n",
      "       ..\n",
      "1979    0\n",
      "2040    0\n",
      "2091    0\n",
      "1763    0\n",
      "2087    0\n",
      "Name: Histological_Type, Length: 831, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831/831 [==============================] - 0s 78us/step - loss: 0.1512 - accuracy: 0.9507\n",
      "Epoch 4/100\n",
      "831/831 [==============================] - 0s 73us/step - loss: 0.1374 - accuracy: 0.9471\n",
      "Epoch 5/100\n",
      "831/831 [==============================] - 0s 69us/step - loss: 0.1230 - accuracy: 0.9591\n",
      "Epoch 6/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.1307 - accuracy: 0.9519\n",
      "Epoch 7/100\n",
      "831/831 [==============================] - 0s 67us/step - loss: 0.1301 - accuracy: 0.9543\n",
      "Epoch 8/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1452 - accuracy: 0.9483\n",
      "Epoch 9/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.1208 - accuracy: 0.9651\n",
      "Epoch 10/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.1202 - accuracy: 0.9579\n",
      "Epoch 11/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1210 - accuracy: 0.9627\n",
      "Epoch 12/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.1299 - accuracy: 0.9519\n",
      "Epoch 13/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.1220 - accuracy: 0.9591\n",
      "Epoch 14/100\n",
      "831/831 [==============================] - 0s 66us/step - loss: 0.1076 - accuracy: 0.9615\n",
      "Epoch 15/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1180 - accuracy: 0.9555\n",
      "Epoch 16/100\n",
      "831/831 [==============================] - 0s 75us/step - loss: 0.1028 - accuracy: 0.9639\n",
      "Epoch 17/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.1082 - accuracy: 0.9627\n",
      "Epoch 18/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.1005 - accuracy: 0.9687\n",
      "Epoch 19/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1129 - accuracy: 0.9591\n",
      "Epoch 20/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1074 - accuracy: 0.9615\n",
      "Epoch 21/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.1086 - accuracy: 0.9639\n",
      "Epoch 22/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.1013 - accuracy: 0.9663\n",
      "Epoch 23/100\n",
      "831/831 [==============================] - 0s 67us/step - loss: 0.0907 - accuracy: 0.9699\n",
      "Epoch 24/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1019 - accuracy: 0.9579\n",
      "Epoch 25/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.1033 - accuracy: 0.9675\n",
      "Epoch 26/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.1006 - accuracy: 0.9675\n",
      "Epoch 27/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.1076 - accuracy: 0.9663\n",
      "Epoch 28/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0950 - accuracy: 0.9651\n",
      "Epoch 29/100\n",
      "831/831 [==============================] - 0s 56us/step - loss: 0.0980 - accuracy: 0.9591\n",
      "Epoch 30/100\n",
      "831/831 [==============================] - 0s 67us/step - loss: 0.0923 - accuracy: 0.9687\n",
      "Epoch 31/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0923 - accuracy: 0.9699\n",
      "Epoch 32/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.1023 - accuracy: 0.9639\n",
      "Epoch 33/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0983 - accuracy: 0.9639\n",
      "Epoch 34/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0807 - accuracy: 0.9687\n",
      "Epoch 35/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0775 - accuracy: 0.9771\n",
      "Epoch 36/100\n",
      "831/831 [==============================] - 0s 71us/step - loss: 0.0767 - accuracy: 0.9759\n",
      "Epoch 37/100\n",
      "831/831 [==============================] - 0s 64us/step - loss: 0.0936 - accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0826 - accuracy: 0.9747\n",
      "Epoch 39/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0915 - accuracy: 0.9651\n",
      "Epoch 40/100\n",
      "831/831 [==============================] - 0s 64us/step - loss: 0.0860 - accuracy: 0.9771\n",
      "Epoch 41/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0849 - accuracy: 0.9699\n",
      "Epoch 42/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0816 - accuracy: 0.9759\n",
      "Epoch 43/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0907 - accuracy: 0.9711\n",
      "Epoch 44/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0751 - accuracy: 0.9795\n",
      "Epoch 45/100\n",
      "831/831 [==============================] - 0s 64us/step - loss: 0.0721 - accuracy: 0.9819\n",
      "Epoch 46/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0766 - accuracy: 0.9675\n",
      "Epoch 47/100\n",
      "831/831 [==============================] - 0s 64us/step - loss: 0.0767 - accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0856 - accuracy: 0.9663\n",
      "Epoch 49/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0811 - accuracy: 0.9711\n",
      "Epoch 50/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0762 - accuracy: 0.9747\n",
      "Epoch 51/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0855 - accuracy: 0.9675\n",
      "Epoch 52/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0764 - accuracy: 0.9735\n",
      "Epoch 53/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0764 - accuracy: 0.9771\n",
      "Epoch 54/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0771 - accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0794 - accuracy: 0.9771\n",
      "Epoch 56/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0677 - accuracy: 0.9807\n",
      "Epoch 57/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0711 - accuracy: 0.9807\n",
      "Epoch 58/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0637 - accuracy: 0.9819\n",
      "Epoch 59/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0728 - accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0663 - accuracy: 0.9819\n",
      "Epoch 61/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0784 - accuracy: 0.9735\n",
      "Epoch 62/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0602 - accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0707 - accuracy: 0.9795\n",
      "Epoch 64/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0888 - accuracy: 0.9711\n",
      "Epoch 65/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0669 - accuracy: 0.9819\n",
      "Epoch 66/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0734 - accuracy: 0.9759\n",
      "Epoch 67/100\n",
      "831/831 [==============================] - 0s 55us/step - loss: 0.0755 - accuracy: 0.9735\n",
      "Epoch 68/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.0625 - accuracy: 0.9819\n",
      "Epoch 69/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0780 - accuracy: 0.9735\n",
      "Epoch 70/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0557 - accuracy: 0.9868\n",
      "Epoch 71/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0663 - accuracy: 0.9807\n",
      "Epoch 72/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0780 - accuracy: 0.9747\n",
      "Epoch 73/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0728 - accuracy: 0.9759\n",
      "Epoch 74/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0635 - accuracy: 0.9807\n",
      "Epoch 75/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0680 - accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "831/831 [==============================] - 0s 56us/step - loss: 0.0597 - accuracy: 0.9807\n",
      "Epoch 77/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0565 - accuracy: 0.9819\n",
      "Epoch 78/100\n",
      "831/831 [==============================] - 0s 56us/step - loss: 0.0691 - accuracy: 0.9807\n",
      "Epoch 79/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.0594 - accuracy: 0.9832\n",
      "Epoch 80/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0714 - accuracy: 0.9735\n",
      "Epoch 81/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0584 - accuracy: 0.9844\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831/831 [==============================] - 0s 56us/step - loss: 0.0673 - accuracy: 0.9807\n",
      "Epoch 83/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.0570 - accuracy: 0.9832\n",
      "Epoch 84/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0621 - accuracy: 0.9795\n",
      "Epoch 85/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0568 - accuracy: 0.9819\n",
      "Epoch 86/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0608 - accuracy: 0.9807\n",
      "Epoch 87/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0637 - accuracy: 0.9832\n",
      "Epoch 88/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0552 - accuracy: 0.9856\n",
      "Epoch 89/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0613 - accuracy: 0.9807\n",
      "Epoch 90/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0594 - accuracy: 0.9795\n",
      "Epoch 91/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0595 - accuracy: 0.9807\n",
      "Epoch 92/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0482 - accuracy: 0.9916\n",
      "Epoch 93/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0577 - accuracy: 0.9819\n",
      "Epoch 94/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0584 - accuracy: 0.9819\n",
      "Epoch 95/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0599 - accuracy: 0.9783\n",
      "Epoch 96/100\n",
      "831/831 [==============================] - 0s 70us/step - loss: 0.0609 - accuracy: 0.9832\n",
      "Epoch 97/100\n",
      "831/831 [==============================] - 0s 72us/step - loss: 0.0596 - accuracy: 0.9807\n",
      "Epoch 98/100\n",
      "831/831 [==============================] - 0s 74us/step - loss: 0.0596 - accuracy: 0.9819\n",
      "Epoch 99/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0532 - accuracy: 0.9904\n",
      "Epoch 100/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0553 - accuracy: 0.9783\n",
      "[[375   6]\n",
      " [ 26   3]]\n",
      "831/831 [==============================] - 0s 28us/step\n",
      "410/410 [==============================] - 0s 41us/step\n",
      "[0.06778845107395798, 0.9651023149490356]\n",
      "[0.26157342442652076, 0.9219512343406677]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.06778845107395798, 0.9651023149490356],\n",
       " [0.26157342442652076, 0.9219512343406677])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn_vk10, X_train_vk10_ND, y_train_vk10_ND, X_test_vk10_ND, y_test_vk10_ND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector-k50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50 = pd.read_csv(\"vector_measures_k50_all_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2233, 370)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_k50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50.rename(columns={\"catalog_ID\": \"METABRIC_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_raw_data_hist = pd.merge(vector_k50, raw_data, on='METABRIC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_raw_data_hist_IDC_ILC = vector_k50_raw_data_hist[(vector_k50_raw_data_hist['Histological_Type'] == 'IDC') | (vector_k50_raw_data_hist['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_hist_IDC_ILC= vector_k50_raw_data_hist_IDC_ILC.iloc[:, 2:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_hist_IDC_ILC =scaler.fit_transform(vector_k50_hist_IDC_ILC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "vector_k50_hist_type = vector_k50_raw_data_hist_IDC_ILC['Histological_Type']\n",
    "vector_k50_hist_type.replace({\"IDC\":0,\"ILC\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vk50, X_test_vk50, y_train_vk50, y_test_vk50 = train_test_split(vector_k50_hist_IDC_ILC, vector_k50_hist_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 0s 65us/step - loss: 0.2184 - accuracy: 0.9217\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.2150 - accuracy: 0.9225\n",
      "Epoch 3/100\n",
      "  32/1264 [..............................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=1755    0\n",
      "988     1\n",
      "210     0\n",
      "1317    0\n",
      "1313    0\n",
      "       ..\n",
      "1421    0\n",
      "1593    0\n",
      "1073    0\n",
      "1762    1\n",
      "1416    0\n",
      "Name: Histological_Type, Length: 1264, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 0s 67us/step - loss: 0.2149 - accuracy: 0.9217\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 0s 62us/step - loss: 0.2181 - accuracy: 0.9153\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1990 - accuracy: 0.9304\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.2021 - accuracy: 0.9256\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.2024 - accuracy: 0.9217\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.2038 - accuracy: 0.9241\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1992 - accuracy: 0.9225\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.2009 - accuracy: 0.9241\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1948 - accuracy: 0.9209\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.2057 - accuracy: 0.9130\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1907 - accuracy: 0.9248\n",
      "Epoch 14/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1816 - accuracy: 0.9280\n",
      "Epoch 15/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1902 - accuracy: 0.9233\n",
      "Epoch 16/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1849 - accuracy: 0.9328\n",
      "Epoch 17/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1844 - accuracy: 0.9343\n",
      "Epoch 18/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1844 - accuracy: 0.9335\n",
      "Epoch 19/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1905 - accuracy: 0.9304\n",
      "Epoch 20/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1863 - accuracy: 0.9296\n",
      "Epoch 21/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1882 - accuracy: 0.9288\n",
      "Epoch 22/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1880 - accuracy: 0.9320\n",
      "Epoch 23/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1823 - accuracy: 0.9328\n",
      "Epoch 24/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9256\n",
      "Epoch 25/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1765 - accuracy: 0.9375\n",
      "Epoch 26/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1702 - accuracy: 0.9335\n",
      "Epoch 27/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1708 - accuracy: 0.9359\n",
      "Epoch 28/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1795 - accuracy: 0.9288\n",
      "Epoch 29/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1774 - accuracy: 0.9328\n",
      "Epoch 30/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1645 - accuracy: 0.9383\n",
      "Epoch 31/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1594 - accuracy: 0.9399\n",
      "Epoch 32/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1686 - accuracy: 0.9280\n",
      "Epoch 33/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.1630 - accuracy: 0.9415\n",
      "Epoch 34/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1663 - accuracy: 0.9383\n",
      "Epoch 35/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1655 - accuracy: 0.9335\n",
      "Epoch 36/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1622 - accuracy: 0.9359\n",
      "Epoch 37/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.1716 - accuracy: 0.9264\n",
      "Epoch 38/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.1628 - accuracy: 0.9399\n",
      "Epoch 39/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1662 - accuracy: 0.9351\n",
      "Epoch 40/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1645 - accuracy: 0.9399\n",
      "Epoch 41/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.1718 - accuracy: 0.9375\n",
      "Epoch 42/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1672 - accuracy: 0.9391\n",
      "Epoch 43/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1579 - accuracy: 0.9399\n",
      "Epoch 44/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.1505 - accuracy: 0.9399\n",
      "Epoch 45/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1636 - accuracy: 0.9367\n",
      "Epoch 46/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1577 - accuracy: 0.9391\n",
      "Epoch 47/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1477 - accuracy: 0.9470\n",
      "Epoch 48/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1568 - accuracy: 0.9415\n",
      "Epoch 49/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1468 - accuracy: 0.9454\n",
      "Epoch 50/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1520 - accuracy: 0.9415\n",
      "Epoch 51/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1557 - accuracy: 0.9422\n",
      "Epoch 52/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1512 - accuracy: 0.9407\n",
      "Epoch 53/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1442 - accuracy: 0.9438\n",
      "Epoch 54/100\n",
      "1264/1264 [==============================] - 0s 58us/step - loss: 0.1498 - accuracy: 0.9454\n",
      "Epoch 55/100\n",
      "1264/1264 [==============================] - 0s 65us/step - loss: 0.1479 - accuracy: 0.9430\n",
      "Epoch 56/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1596 - accuracy: 0.9399\n",
      "Epoch 57/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.1526 - accuracy: 0.9422\n",
      "Epoch 58/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1403 - accuracy: 0.9525\n",
      "Epoch 59/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1417 - accuracy: 0.9541\n",
      "Epoch 60/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1447 - accuracy: 0.9486\n",
      "Epoch 61/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1436 - accuracy: 0.9509\n",
      "Epoch 62/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.1337 - accuracy: 0.9525\n",
      "Epoch 63/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.1448 - accuracy: 0.9478\n",
      "Epoch 64/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.1398 - accuracy: 0.9478\n",
      "Epoch 65/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1473 - accuracy: 0.9494\n",
      "Epoch 66/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1371 - accuracy: 0.9525\n",
      "Epoch 67/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1429 - accuracy: 0.9478\n",
      "Epoch 68/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1355 - accuracy: 0.9517\n",
      "Epoch 69/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1383 - accuracy: 0.9478\n",
      "Epoch 70/100\n",
      "1264/1264 [==============================] - 0s 65us/step - loss: 0.1393 - accuracy: 0.9446\n",
      "Epoch 71/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1320 - accuracy: 0.9525\n",
      "Epoch 72/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1409 - accuracy: 0.9486\n",
      "Epoch 73/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.1444 - accuracy: 0.9446\n",
      "Epoch 74/100\n",
      "1264/1264 [==============================] - 0s 60us/step - loss: 0.1402 - accuracy: 0.9509\n",
      "Epoch 75/100\n",
      "1264/1264 [==============================] - 0s 67us/step - loss: 0.1373 - accuracy: 0.9517\n",
      "Epoch 76/100\n",
      "1264/1264 [==============================] - 0s 67us/step - loss: 0.1269 - accuracy: 0.9494\n",
      "Epoch 77/100\n",
      "1264/1264 [==============================] - 0s 68us/step - loss: 0.1310 - accuracy: 0.9533\n",
      "Epoch 78/100\n",
      "1264/1264 [==============================] - 0s 65us/step - loss: 0.1261 - accuracy: 0.9517\n",
      "Epoch 79/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.1263 - accuracy: 0.9541\n",
      "Epoch 80/100\n",
      "1264/1264 [==============================] - 0s 73us/step - loss: 0.1319 - accuracy: 0.9533\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 0s 75us/step - loss: 0.1233 - accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "1264/1264 [==============================] - 0s 63us/step - loss: 0.1310 - accuracy: 0.9517\n",
      "Epoch 83/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1202 - accuracy: 0.9557\n",
      "Epoch 84/100\n",
      "1264/1264 [==============================] - 0s 61us/step - loss: 0.1199 - accuracy: 0.9557\n",
      "Epoch 85/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1195 - accuracy: 0.9573\n",
      "Epoch 86/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1324 - accuracy: 0.9446\n",
      "Epoch 87/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1159 - accuracy: 0.9565\n",
      "Epoch 88/100\n",
      "1264/1264 [==============================] - 0s 59us/step - loss: 0.1161 - accuracy: 0.9541\n",
      "Epoch 89/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1175 - accuracy: 0.9581\n",
      "Epoch 90/100\n",
      "1264/1264 [==============================] - 0s 57us/step - loss: 0.1214 - accuracy: 0.9565\n",
      "Epoch 91/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1187 - accuracy: 0.9541\n",
      "Epoch 92/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1296 - accuracy: 0.9517\n",
      "Epoch 93/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1140 - accuracy: 0.9549\n",
      "Epoch 94/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1256 - accuracy: 0.9565\n",
      "Epoch 95/100\n",
      "1264/1264 [==============================] - 0s 54us/step - loss: 0.1319 - accuracy: 0.9502\n",
      "Epoch 96/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1119 - accuracy: 0.9620\n",
      "Epoch 97/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1104 - accuracy: 0.9581\n",
      "Epoch 98/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1124 - accuracy: 0.9573\n",
      "Epoch 99/100\n",
      "1264/1264 [==============================] - 0s 56us/step - loss: 0.1154 - accuracy: 0.9565\n",
      "Epoch 100/100\n",
      "1264/1264 [==============================] - 0s 55us/step - loss: 0.1180 - accuracy: 0.9549\n",
      "[[490  74]\n",
      " [ 41  19]]\n",
      "1264/1264 [==============================] - 0s 24us/step\n",
      "624/624 [==============================] - 0s 30us/step\n",
      "[0.19888092388835135, 0.9193037748336792]\n",
      "[0.4579248535327422, 0.8157051205635071]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.19888092388835135, 0.9193037748336792],\n",
       " [0.4579248535327422, 0.8157051205635071])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn_vk10, X_train_vk50, y_train_vk50, X_test_vk50, y_test_vk50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector-k50 No Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_raw_data_hist_IDC_ILC_ND = vector_k50_raw_data_hist_IDC_ILC.drop_duplicates(subset=['METABRIC_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241, 2403)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_k50_raw_data_hist_IDC_ILC_ND.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_hist_IDC_ILC_ND = vector_k50_raw_data_hist_IDC_ILC_ND.iloc[:, 2:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_hist_IDC_ILC_ND =scaler.fit_transform(vector_k50_hist_IDC_ILC_ND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_k50_hist_type_ND = vector_k50_raw_data_hist_IDC_ILC_ND['Histological_Type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vk50_ND, X_test_vk50_ND, y_train_vk50_ND, y_test_vk50_ND = train_test_split(vector_k50_hist_IDC_ILC_ND, vector_k50_hist_type_ND, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.0455 - accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "831/831 [==============================] - 0s 81us/step - loss: 0.0455 - accuracy: 0.9880\n",
      "Epoch 3/100\n",
      "831/831 [==============================] - 0s 75us/step - loss: 0.0659 - accuracy: 0.9771\n",
      "Epoch 4/100\n",
      " 32/831 [>.............................] - ETA: 0s - loss: 0.0468 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=976     0\n",
      "71      0\n",
      "1075    0\n",
      "1417    0\n",
      "115     0\n",
      "       ..\n",
      "1979    0\n",
      "2040    0\n",
      "2091    0\n",
      "1763    0\n",
      "2087    0\n",
      "Name: Histological_Type, Length: 831, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831/831 [==============================] - 0s 77us/step - loss: 0.0577 - accuracy: 0.9819\n",
      "Epoch 5/100\n",
      "831/831 [==============================] - 0s 75us/step - loss: 0.0570 - accuracy: 0.9832\n",
      "Epoch 6/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0539 - accuracy: 0.9832\n",
      "Epoch 7/100\n",
      "831/831 [==============================] - 0s 67us/step - loss: 0.0528 - accuracy: 0.9844\n",
      "Epoch 8/100\n",
      "831/831 [==============================] - 0s 82us/step - loss: 0.0595 - accuracy: 0.9795\n",
      "Epoch 9/100\n",
      "831/831 [==============================] - 0s 75us/step - loss: 0.0568 - accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0581 - accuracy: 0.9868\n",
      "Epoch 11/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0485 - accuracy: 0.9832\n",
      "Epoch 12/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0484 - accuracy: 0.9868\n",
      "Epoch 13/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0531 - accuracy: 0.9868\n",
      "Epoch 14/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0534 - accuracy: 0.9807\n",
      "Epoch 15/100\n",
      "831/831 [==============================] - 0s 93us/step - loss: 0.0599 - accuracy: 0.9795\n",
      "Epoch 16/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0517 - accuracy: 0.9868\n",
      "Epoch 17/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.0501 - accuracy: 0.9868\n",
      "Epoch 18/100\n",
      "831/831 [==============================] - 0s 70us/step - loss: 0.0501 - accuracy: 0.9856\n",
      "Epoch 19/100\n",
      "831/831 [==============================] - 0s 80us/step - loss: 0.0412 - accuracy: 0.9892\n",
      "Epoch 20/100\n",
      "831/831 [==============================] - 0s 77us/step - loss: 0.0481 - accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "831/831 [==============================] - 0s 71us/step - loss: 0.0507 - accuracy: 0.9880\n",
      "Epoch 22/100\n",
      "831/831 [==============================] - 0s 80us/step - loss: 0.0515 - accuracy: 0.9868\n",
      "Epoch 23/100\n",
      "831/831 [==============================] - 0s 76us/step - loss: 0.0528 - accuracy: 0.9844\n",
      "Epoch 24/100\n",
      "831/831 [==============================] - 0s 76us/step - loss: 0.0543 - accuracy: 0.9819\n",
      "Epoch 25/100\n",
      "831/831 [==============================] - 0s 79us/step - loss: 0.0565 - accuracy: 0.9807\n",
      "Epoch 26/100\n",
      "831/831 [==============================] - 0s 102us/step - loss: 0.0520 - accuracy: 0.9892\n",
      "Epoch 27/100\n",
      "831/831 [==============================] - 0s 82us/step - loss: 0.0576 - accuracy: 0.9868\n",
      "Epoch 28/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.0460 - accuracy: 0.9904\n",
      "Epoch 29/100\n",
      "831/831 [==============================] - 0s 78us/step - loss: 0.0452 - accuracy: 0.9868\n",
      "Epoch 30/100\n",
      "831/831 [==============================] - 0s 77us/step - loss: 0.0474 - accuracy: 0.9844\n",
      "Epoch 31/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.0419 - accuracy: 0.9880\n",
      "Epoch 32/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0514 - accuracy: 0.9856\n",
      "Epoch 33/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0488 - accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0473 - accuracy: 0.9880\n",
      "Epoch 35/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0419 - accuracy: 0.9892\n",
      "Epoch 36/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.0409 - accuracy: 0.9916\n",
      "Epoch 37/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0448 - accuracy: 0.9904\n",
      "Epoch 38/100\n",
      "831/831 [==============================] - 0s 69us/step - loss: 0.0387 - accuracy: 0.9928\n",
      "Epoch 39/100\n",
      "831/831 [==============================] - 0s 78us/step - loss: 0.0368 - accuracy: 0.9916\n",
      "Epoch 40/100\n",
      "831/831 [==============================] - 0s 77us/step - loss: 0.0397 - accuracy: 0.9892\n",
      "Epoch 41/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.0456 - accuracy: 0.9856\n",
      "Epoch 42/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0462 - accuracy: 0.9880\n",
      "Epoch 43/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0390 - accuracy: 0.9904\n",
      "Epoch 44/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 45/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0440 - accuracy: 0.9844\n",
      "Epoch 46/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0401 - accuracy: 0.9916\n",
      "Epoch 47/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0525 - accuracy: 0.9868\n",
      "Epoch 48/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0366 - accuracy: 0.9940\n",
      "Epoch 49/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0352 - accuracy: 0.9916\n",
      "Epoch 50/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 51/100\n",
      "831/831 [==============================] - 0s 64us/step - loss: 0.0422 - accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0480 - accuracy: 0.9868\n",
      "Epoch 53/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0502 - accuracy: 0.9844\n",
      "Epoch 54/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0336 - accuracy: 0.9928\n",
      "Epoch 55/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0344 - accuracy: 0.9916\n",
      "Epoch 56/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0460 - accuracy: 0.9868\n",
      "Epoch 57/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0384 - accuracy: 0.9940\n",
      "Epoch 58/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0392 - accuracy: 0.9868\n",
      "Epoch 59/100\n",
      "831/831 [==============================] - 0s 74us/step - loss: 0.0470 - accuracy: 0.9783\n",
      "Epoch 60/100\n",
      "831/831 [==============================] - 0s 75us/step - loss: 0.0355 - accuracy: 0.9940\n",
      "Epoch 61/100\n",
      "831/831 [==============================] - 0s 76us/step - loss: 0.0388 - accuracy: 0.9916\n",
      "Epoch 62/100\n",
      "831/831 [==============================] - 0s 75us/step - loss: 0.0397 - accuracy: 0.9916\n",
      "Epoch 63/100\n",
      "831/831 [==============================] - 0s 71us/step - loss: 0.0345 - accuracy: 0.9928\n",
      "Epoch 64/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0338 - accuracy: 0.9928\n",
      "Epoch 65/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0459 - accuracy: 0.9856\n",
      "Epoch 66/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0354 - accuracy: 0.9916\n",
      "Epoch 67/100\n",
      "831/831 [==============================] - 0s 57us/step - loss: 0.0328 - accuracy: 0.9940\n",
      "Epoch 68/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0404 - accuracy: 0.9880\n",
      "Epoch 69/100\n",
      "831/831 [==============================] - 0s 62us/step - loss: 0.0373 - accuracy: 0.9904\n",
      "Epoch 70/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0334 - accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "831/831 [==============================] - 0s 59us/step - loss: 0.0368 - accuracy: 0.9916\n",
      "Epoch 72/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.0434 - accuracy: 0.9868\n",
      "Epoch 73/100\n",
      "831/831 [==============================] - 0s 67us/step - loss: 0.0317 - accuracy: 0.9928\n",
      "Epoch 74/100\n",
      "831/831 [==============================] - 0s 71us/step - loss: 0.0391 - accuracy: 0.9904\n",
      "Epoch 75/100\n",
      "831/831 [==============================] - 0s 76us/step - loss: 0.0449 - accuracy: 0.9880\n",
      "Epoch 76/100\n",
      "831/831 [==============================] - 0s 73us/step - loss: 0.0336 - accuracy: 0.9928\n",
      "Epoch 77/100\n",
      "831/831 [==============================] - 0s 71us/step - loss: 0.0319 - accuracy: 0.9952\n",
      "Epoch 78/100\n",
      "831/831 [==============================] - 0s 74us/step - loss: 0.0336 - accuracy: 0.9916\n",
      "Epoch 79/100\n",
      "831/831 [==============================] - 0s 77us/step - loss: 0.0368 - accuracy: 0.9904\n",
      "Epoch 80/100\n",
      "831/831 [==============================] - 0s 66us/step - loss: 0.0334 - accuracy: 0.9928\n",
      "Epoch 81/100\n",
      "831/831 [==============================] - 0s 64us/step - loss: 0.0324 - accuracy: 0.9952\n",
      "Epoch 82/100\n",
      "831/831 [==============================] - 0s 73us/step - loss: 0.0406 - accuracy: 0.9856\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831/831 [==============================] - 0s 73us/step - loss: 0.0301 - accuracy: 0.9976\n",
      "Epoch 84/100\n",
      "831/831 [==============================] - 0s 82us/step - loss: 0.0440 - accuracy: 0.9880\n",
      "Epoch 85/100\n",
      "831/831 [==============================] - 0s 74us/step - loss: 0.0316 - accuracy: 0.9928\n",
      "Epoch 86/100\n",
      "831/831 [==============================] - 0s 70us/step - loss: 0.0314 - accuracy: 0.9916\n",
      "Epoch 87/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0382 - accuracy: 0.9880\n",
      "Epoch 88/100\n",
      "831/831 [==============================] - 0s 60us/step - loss: 0.0388 - accuracy: 0.9904\n",
      "Epoch 89/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0371 - accuracy: 0.9904\n",
      "Epoch 90/100\n",
      "831/831 [==============================] - 0s 66us/step - loss: 0.0404 - accuracy: 0.9868\n",
      "Epoch 91/100\n",
      "831/831 [==============================] - 0s 72us/step - loss: 0.0353 - accuracy: 0.9892\n",
      "Epoch 92/100\n",
      "831/831 [==============================] - 0s 65us/step - loss: 0.0348 - accuracy: 0.9940\n",
      "Epoch 93/100\n",
      "831/831 [==============================] - 0s 61us/step - loss: 0.0352 - accuracy: 0.9916\n",
      "Epoch 94/100\n",
      "831/831 [==============================] - 0s 58us/step - loss: 0.0381 - accuracy: 0.9904\n",
      "Epoch 95/100\n",
      "831/831 [==============================] - 0s 56us/step - loss: 0.0337 - accuracy: 0.9928\n",
      "Epoch 96/100\n",
      "831/831 [==============================] - 0s 63us/step - loss: 0.0409 - accuracy: 0.9844\n",
      "Epoch 97/100\n",
      "831/831 [==============================] - 0s 72us/step - loss: 0.0347 - accuracy: 0.9916\n",
      "Epoch 98/100\n",
      "831/831 [==============================] - 0s 66us/step - loss: 0.0400 - accuracy: 0.9892\n",
      "Epoch 99/100\n",
      "831/831 [==============================] - 0s 68us/step - loss: 0.0362 - accuracy: 0.9928\n",
      "Epoch 100/100\n",
      "831/831 [==============================] - 0s 74us/step - loss: 0.0287 - accuracy: 0.9916\n",
      "[[360  21]\n",
      " [ 20   9]]\n",
      "831/831 [==============================] - 0s 35us/step\n",
      "410/410 [==============================] - 0s 41us/step\n",
      "[0.05271818614357502, 0.9807460904121399]\n",
      "[0.31662664180848654, 0.8999999761581421]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.05271818614357502, 0.9807460904121399],\n",
       " [0.31662664180848654, 0.8999999761581421])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores(dnn_vk10, X_train_vk10_ND, y_train_vk10_ND, X_test_vk10_ND, y_test_vk10_ND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting PAM50 with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2233, 2047)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k50_raw_data_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>METABRIC_ID</th>\n",
       "      <th>Rho_0</th>\n",
       "      <th>Rho_1</th>\n",
       "      <th>Rho_2</th>\n",
       "      <th>Rho_G</th>\n",
       "      <th>S_0_mean</th>\n",
       "      <th>S_1_mean</th>\n",
       "      <th>S_2_mean</th>\n",
       "      <th>S_G_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>CNA_FOXM1</th>\n",
       "      <th>CNA_EXOC3</th>\n",
       "      <th>CNA_ARMC7</th>\n",
       "      <th>CNA_KCTD2</th>\n",
       "      <th>CNA_PDCD10</th>\n",
       "      <th>CNA_RHOD</th>\n",
       "      <th>CNA_CFL1</th>\n",
       "      <th>CNA_YBX1</th>\n",
       "      <th>CNA_TRIM24</th>\n",
       "      <th>CNA_RAB11FIP3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MB-0000</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>1.145475</td>\n",
       "      <td>1.056243</td>\n",
       "      <td>1.195134</td>\n",
       "      <td>1.158202</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MB-0000</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>1.176672</td>\n",
       "      <td>1.216936</td>\n",
       "      <td>1.136966</td>\n",
       "      <td>1.101973</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MB-0002</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.027961</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>1.199663</td>\n",
       "      <td>1.035566</td>\n",
       "      <td>1.207598</td>\n",
       "      <td>1.159850</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MB-0002</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.018164</td>\n",
       "      <td>0.053973</td>\n",
       "      <td>0.036947</td>\n",
       "      <td>1.162653</td>\n",
       "      <td>1.189897</td>\n",
       "      <td>1.168013</td>\n",
       "      <td>1.123325</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MB-0005</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.058920</td>\n",
       "      <td>0.055510</td>\n",
       "      <td>1.154258</td>\n",
       "      <td>1.057857</td>\n",
       "      <td>1.126286</td>\n",
       "      <td>1.107860</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>914</td>\n",
       "      <td>MB-6344</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>1.258155</td>\n",
       "      <td>1.202329</td>\n",
       "      <td>1.255615</td>\n",
       "      <td>1.170257</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>915</td>\n",
       "      <td>MB-6346</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>1.274999</td>\n",
       "      <td>1.218476</td>\n",
       "      <td>1.324986</td>\n",
       "      <td>1.221752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>916</td>\n",
       "      <td>MB-6358</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>1.309905</td>\n",
       "      <td>1.168389</td>\n",
       "      <td>1.285276</td>\n",
       "      <td>1.235523</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>917</td>\n",
       "      <td>MB-6359</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>1.186501</td>\n",
       "      <td>1.113902</td>\n",
       "      <td>1.201378</td>\n",
       "      <td>1.147735</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>918</td>\n",
       "      <td>MB-6363</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>1.213852</td>\n",
       "      <td>1.133489</td>\n",
       "      <td>1.257477</td>\n",
       "      <td>1.158222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2228 rows × 2047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index METABRIC_ID     Rho_0     Rho_1     Rho_2     Rho_G  S_0_mean  \\\n",
       "0         0     MB-0000  0.011658  0.011032  0.057107  0.051694  1.145475   \n",
       "1         1     MB-0000  0.009941  0.012683  0.036212  0.016585  1.176672   \n",
       "2         2     MB-0002  0.003012  0.005472  0.027961  0.025023  1.199663   \n",
       "3         3     MB-0002  0.011538  0.018164  0.053973  0.036947  1.162653   \n",
       "4         4     MB-0005  0.006785  0.005110  0.058920  0.055510  1.154258   \n",
       "...     ...         ...       ...       ...       ...       ...       ...   \n",
       "2228    914     MB-6344  0.002257  0.003141  0.001169  0.002043  1.258155   \n",
       "2229    915     MB-6346  0.002072  0.003179  0.001560  0.002025  1.274999   \n",
       "2230    916     MB-6358  0.002085  0.001883  0.001762  0.001814  1.309905   \n",
       "2231    917     MB-6359  0.003421  0.003395  0.002527  0.002961  1.186501   \n",
       "2232    918     MB-6363  0.000979  0.001256  0.000861  0.000904  1.213852   \n",
       "\n",
       "      S_1_mean  S_2_mean  S_G_mean  ...  CNA_FOXM1  CNA_EXOC3  CNA_ARMC7  \\\n",
       "0     1.056243  1.195134  1.158202  ...          0          0          0   \n",
       "1     1.216936  1.136966  1.101973  ...          0          0          0   \n",
       "2     1.035566  1.207598  1.159850  ...          0          0         -1   \n",
       "3     1.189897  1.168013  1.123325  ...          0          0         -1   \n",
       "4     1.057857  1.126286  1.107860  ...          0          0          0   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "2228  1.202329  1.255615  1.170257  ...          0          0          1   \n",
       "2229  1.218476  1.324986  1.221752  ...          0          0          0   \n",
       "2230  1.168389  1.285276  1.235523  ...          0          2         -1   \n",
       "2231  1.113902  1.201378  1.147735  ...          0         -1          1   \n",
       "2232  1.133489  1.257477  1.158222  ...          0          0          0   \n",
       "\n",
       "      CNA_KCTD2  CNA_PDCD10  CNA_RHOD CNA_CFL1 CNA_YBX1 CNA_TRIM24  \\\n",
       "0             0           0         0        0        0          0   \n",
       "1             0           0         0        0        0          0   \n",
       "2            -1           0         2        2        0         -1   \n",
       "3            -1           0         2        2        0         -1   \n",
       "4             0           0         1        1        0          2   \n",
       "...         ...         ...       ...      ...      ...        ...   \n",
       "2228          1           0         0        0       -1         -1   \n",
       "2229          0           0         0        0        0         -1   \n",
       "2230         -1           0         0        0        1          0   \n",
       "2231          1           0        -1       -1        0          0   \n",
       "2232          0           0         0        0        0          0   \n",
       "\n",
       "      CNA_RAB11FIP3  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 1  \n",
       "...             ...  \n",
       "2228              0  \n",
       "2229              0  \n",
       "2230              1  \n",
       "2231              1  \n",
       "2232              0  \n",
       "\n",
       "[2228 rows x 2047 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_k50_raw_data_hist[scalar_k50_raw_data_hist.Pam50Subtype != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'LumB',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumB',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'LumA',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Basal',\n",
       " 'Normal',\n",
       " 'Normal',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'Her2',\n",
       " 'Her2',\n",
       " 'Normal',\n",
       " 'Basal',\n",
       " 'LumB',\n",
       " 'LumB',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " 'LumA',\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "g= list(scalar_k50_raw_data_hist[\"Pam50Subtype\"].values)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Maja's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (15,16,18,20,21,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "MBdata_all_genes = pd.read_csv(\"MBdata_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 25403)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MBdata_all_genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MBdata_all_genes_IDC_ILC = MBdata_all_genes[(MBdata_all_genes['Histological_Type'] == 'IDC') | (MBdata_all_genes['Histological_Type'] == 'ILC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = MBdata_all_genes_IDC_ILC.iloc[:,35: 24403]\n",
    "all_genes = scaler.fit_transform(all_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1975    0\n",
       "1976    1\n",
       "1977    0\n",
       "1978    0\n",
       "1979    1\n",
       "Name: Histological_Type, Length: 1694, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(all_genes, hist_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 876us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 856us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 852us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 846us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 839us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 852us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 862us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 873us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 863us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 872us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 856us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 856us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 854us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 861us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 848us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 900us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 925us/step - loss: nan - accuracy: 0.9101\n",
      "Epoch 19/100\n",
      " 512/1134 [============>.................] - ETA: 0s - loss: nan - accuracy: 0.9043"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-7dfc883a2415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-fb7f2a277669>\u001b[0m in \u001b[0;36mmodel_scores\u001b[0;34m(dnn, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0my_test_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_scores(dnn_all, X_train_m, y_train_m, X_test_m,y_test_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR using all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1378\n",
       "1     602\n",
       "Name: DR, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr = raw_data[\"DR\"]\n",
    "dr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dr, X_test_dr, y_train_dr, y_test_dr = train_test_split(MB_all_genes, dr, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohrehwmac/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=1719    1\n",
      "451     0\n",
      "490     0\n",
      "1465    1\n",
      "287     0\n",
      "       ..\n",
      "1130    0\n",
      "1294    0\n",
      "860     0\n",
      "1459    0\n",
      "1126    1\n",
      "Name: DR, Length: 1326, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_ge\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        (None, 24368)             0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 256)               6238464   \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,256,322\n",
      "Trainable params: 6,255,682\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1326/1326 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.6923\n",
      "Epoch 2/5\n",
      "1326/1326 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.6961\n",
      "Epoch 3/5\n",
      "1326/1326 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.6961A: 0s - loss: nan - accuracy: 0\n",
      "Epoch 4/5\n",
      "1326/1326 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.6961\n",
      "Epoch 5/5\n",
      "1326/1326 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.6961\n",
      "[[455   0]\n",
      " [199   0]]\n",
      "1326/1326 [==============================] - 1s 618us/step\n",
      "654/654 [==============================] - 0s 560us/step\n",
      "[nan, 0.6960784196853638]\n",
      "[nan, 0.6957186460494995]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([nan, 0.6960784196853638], [nan, 0.6957186460494995])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(X_train_dr, y_train_dr, X_test_dr, y_test_dr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notepad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CURTIS_data_Expression.txt\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24368, 1982)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=list(df[\"SYMBOL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop([\"SYMBOL\",\"ENTREZ\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed=new_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 24368)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed.columns=col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RERE</th>\n",
       "      <th>RNF165</th>\n",
       "      <th>CD049690</th>\n",
       "      <th>BC033982</th>\n",
       "      <th>PHF7</th>\n",
       "      <th>CIDEA</th>\n",
       "      <th>PAPD4</th>\n",
       "      <th>AI082173</th>\n",
       "      <th>SLC17A3</th>\n",
       "      <th>SDS</th>\n",
       "      <th>...</th>\n",
       "      <th>BX115874</th>\n",
       "      <th>BX107598</th>\n",
       "      <th>UGCGL1</th>\n",
       "      <th>VPS72</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>CC2D1A</th>\n",
       "      <th>CB986545</th>\n",
       "      <th>IGSF9</th>\n",
       "      <th>DA110839</th>\n",
       "      <th>FAM71A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MB-0362</th>\n",
       "      <td>8.676978</td>\n",
       "      <td>6.075331</td>\n",
       "      <td>5.453928</td>\n",
       "      <td>4.994525</td>\n",
       "      <td>5.838270</td>\n",
       "      <td>6.397503</td>\n",
       "      <td>7.906217</td>\n",
       "      <td>5.259461</td>\n",
       "      <td>5.702379</td>\n",
       "      <td>6.930741</td>\n",
       "      <td>...</td>\n",
       "      <td>5.271343</td>\n",
       "      <td>5.680321</td>\n",
       "      <td>7.688492</td>\n",
       "      <td>8.084979</td>\n",
       "      <td>5.161796</td>\n",
       "      <td>6.353215</td>\n",
       "      <td>4.836483</td>\n",
       "      <td>7.304643</td>\n",
       "      <td>5.251843</td>\n",
       "      <td>5.049591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0346</th>\n",
       "      <td>9.653589</td>\n",
       "      <td>6.687887</td>\n",
       "      <td>5.454185</td>\n",
       "      <td>5.346010</td>\n",
       "      <td>5.600876</td>\n",
       "      <td>5.246319</td>\n",
       "      <td>8.267256</td>\n",
       "      <td>5.380069</td>\n",
       "      <td>5.521794</td>\n",
       "      <td>6.141689</td>\n",
       "      <td>...</td>\n",
       "      <td>5.942887</td>\n",
       "      <td>5.461069</td>\n",
       "      <td>7.804165</td>\n",
       "      <td>8.349115</td>\n",
       "      <td>5.197392</td>\n",
       "      <td>6.132355</td>\n",
       "      <td>5.316819</td>\n",
       "      <td>7.933324</td>\n",
       "      <td>5.450611</td>\n",
       "      <td>5.316790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0386</th>\n",
       "      <td>9.033589</td>\n",
       "      <td>5.910885</td>\n",
       "      <td>5.501577</td>\n",
       "      <td>5.247467</td>\n",
       "      <td>6.030718</td>\n",
       "      <td>10.111816</td>\n",
       "      <td>7.959291</td>\n",
       "      <td>5.262024</td>\n",
       "      <td>5.689533</td>\n",
       "      <td>6.529312</td>\n",
       "      <td>...</td>\n",
       "      <td>5.174498</td>\n",
       "      <td>5.304030</td>\n",
       "      <td>7.934309</td>\n",
       "      <td>8.406332</td>\n",
       "      <td>8.087722</td>\n",
       "      <td>6.366335</td>\n",
       "      <td>5.466419</td>\n",
       "      <td>7.580336</td>\n",
       "      <td>5.235394</td>\n",
       "      <td>5.461617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0574</th>\n",
       "      <td>8.814855</td>\n",
       "      <td>5.628740</td>\n",
       "      <td>5.471941</td>\n",
       "      <td>5.316523</td>\n",
       "      <td>5.849428</td>\n",
       "      <td>6.116868</td>\n",
       "      <td>9.206376</td>\n",
       "      <td>5.396576</td>\n",
       "      <td>5.439130</td>\n",
       "      <td>6.430102</td>\n",
       "      <td>...</td>\n",
       "      <td>5.116749</td>\n",
       "      <td>5.632249</td>\n",
       "      <td>7.744562</td>\n",
       "      <td>8.310019</td>\n",
       "      <td>5.780062</td>\n",
       "      <td>6.424048</td>\n",
       "      <td>5.193150</td>\n",
       "      <td>6.903654</td>\n",
       "      <td>5.091927</td>\n",
       "      <td>5.227130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0185</th>\n",
       "      <td>8.736406</td>\n",
       "      <td>6.392422</td>\n",
       "      <td>5.525027</td>\n",
       "      <td>5.032408</td>\n",
       "      <td>5.542133</td>\n",
       "      <td>5.184098</td>\n",
       "      <td>8.162845</td>\n",
       "      <td>5.485314</td>\n",
       "      <td>5.464326</td>\n",
       "      <td>6.105427</td>\n",
       "      <td>...</td>\n",
       "      <td>5.411248</td>\n",
       "      <td>5.638010</td>\n",
       "      <td>7.613439</td>\n",
       "      <td>8.161977</td>\n",
       "      <td>5.327687</td>\n",
       "      <td>6.252966</td>\n",
       "      <td>5.299070</td>\n",
       "      <td>6.848395</td>\n",
       "      <td>5.238651</td>\n",
       "      <td>5.057761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             RERE    RNF165  CD049690  BC033982      PHF7      CIDEA  \\\n",
       "MB-0362  8.676978  6.075331  5.453928  4.994525  5.838270   6.397503   \n",
       "MB-0346  9.653589  6.687887  5.454185  5.346010  5.600876   5.246319   \n",
       "MB-0386  9.033589  5.910885  5.501577  5.247467  6.030718  10.111816   \n",
       "MB-0574  8.814855  5.628740  5.471941  5.316523  5.849428   6.116868   \n",
       "MB-0185  8.736406  6.392422  5.525027  5.032408  5.542133   5.184098   \n",
       "\n",
       "            PAPD4  AI082173   SLC17A3       SDS  ...  BX115874  BX107598  \\\n",
       "MB-0362  7.906217  5.259461  5.702379  6.930741  ...  5.271343  5.680321   \n",
       "MB-0346  8.267256  5.380069  5.521794  6.141689  ...  5.942887  5.461069   \n",
       "MB-0386  7.959291  5.262024  5.689533  6.529312  ...  5.174498  5.304030   \n",
       "MB-0574  9.206376  5.396576  5.439130  6.430102  ...  5.116749  5.632249   \n",
       "MB-0185  8.162845  5.485314  5.464326  6.105427  ...  5.411248  5.638010   \n",
       "\n",
       "           UGCGL1     VPS72     CSMD3    CC2D1A  CB986545     IGSF9  DA110839  \\\n",
       "MB-0362  7.688492  8.084979  5.161796  6.353215  4.836483  7.304643  5.251843   \n",
       "MB-0346  7.804165  8.349115  5.197392  6.132355  5.316819  7.933324  5.450611   \n",
       "MB-0386  7.934309  8.406332  8.087722  6.366335  5.466419  7.580336  5.235394   \n",
       "MB-0574  7.744562  8.310019  5.780062  6.424048  5.193150  6.903654  5.091927   \n",
       "MB-0185  7.613439  8.161977  5.327687  6.252966  5.299070  6.848395  5.238651   \n",
       "\n",
       "           FAM71A  \n",
       "MB-0362  5.049591  \n",
       "MB-0346  5.316790  \n",
       "MB-0386  5.461617  \n",
       "MB-0574  5.227130  \n",
       "MB-0185  5.057761  \n",
       "\n",
       "[5 rows x 24368 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised = scaler.fit_transform(transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to_df = pd.DataFrame(normalised, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RERE</th>\n",
       "      <th>RNF165</th>\n",
       "      <th>CD049690</th>\n",
       "      <th>BC033982</th>\n",
       "      <th>PHF7</th>\n",
       "      <th>CIDEA</th>\n",
       "      <th>PAPD4</th>\n",
       "      <th>AI082173</th>\n",
       "      <th>SLC17A3</th>\n",
       "      <th>SDS</th>\n",
       "      <th>...</th>\n",
       "      <th>BX115874</th>\n",
       "      <th>BX107598</th>\n",
       "      <th>UGCGL1</th>\n",
       "      <th>VPS72</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>CC2D1A</th>\n",
       "      <th>CB986545</th>\n",
       "      <th>IGSF9</th>\n",
       "      <th>DA110839</th>\n",
       "      <th>FAM71A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390897</td>\n",
       "      <td>0.191780</td>\n",
       "      <td>0.438119</td>\n",
       "      <td>0.209212</td>\n",
       "      <td>0.258926</td>\n",
       "      <td>0.206795</td>\n",
       "      <td>0.520822</td>\n",
       "      <td>0.457770</td>\n",
       "      <td>0.219569</td>\n",
       "      <td>0.388257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160475</td>\n",
       "      <td>0.574384</td>\n",
       "      <td>0.409407</td>\n",
       "      <td>0.230384</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>0.237595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441343</td>\n",
       "      <td>0.249890</td>\n",
       "      <td>0.194661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.668317</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>0.438309</td>\n",
       "      <td>0.547825</td>\n",
       "      <td>0.157221</td>\n",
       "      <td>0.055471</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.580557</td>\n",
       "      <td>0.145330</td>\n",
       "      <td>0.207238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393106</td>\n",
       "      <td>0.402749</td>\n",
       "      <td>0.438106</td>\n",
       "      <td>0.297953</td>\n",
       "      <td>0.058445</td>\n",
       "      <td>0.164547</td>\n",
       "      <td>0.421255</td>\n",
       "      <td>0.570461</td>\n",
       "      <td>0.395704</td>\n",
       "      <td>0.330956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.492197</td>\n",
       "      <td>0.158484</td>\n",
       "      <td>0.473315</td>\n",
       "      <td>0.452891</td>\n",
       "      <td>0.341374</td>\n",
       "      <td>0.695042</td>\n",
       "      <td>0.534299</td>\n",
       "      <td>0.460380</td>\n",
       "      <td>0.214288</td>\n",
       "      <td>0.296164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126927</td>\n",
       "      <td>0.279815</td>\n",
       "      <td>0.470394</td>\n",
       "      <td>0.312589</td>\n",
       "      <td>0.535862</td>\n",
       "      <td>0.241934</td>\n",
       "      <td>0.552454</td>\n",
       "      <td>0.497964</td>\n",
       "      <td>0.237824</td>\n",
       "      <td>0.404830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430063</td>\n",
       "      <td>0.101357</td>\n",
       "      <td>0.451425</td>\n",
       "      <td>0.519418</td>\n",
       "      <td>0.263706</td>\n",
       "      <td>0.169905</td>\n",
       "      <td>0.850969</td>\n",
       "      <td>0.597362</td>\n",
       "      <td>0.111346</td>\n",
       "      <td>0.273404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>0.536752</td>\n",
       "      <td>0.423318</td>\n",
       "      <td>0.287952</td>\n",
       "      <td>0.154689</td>\n",
       "      <td>0.261022</td>\n",
       "      <td>0.312797</td>\n",
       "      <td>0.358988</td>\n",
       "      <td>0.132578</td>\n",
       "      <td>0.285221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407779</td>\n",
       "      <td>0.255982</td>\n",
       "      <td>0.490636</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.132055</td>\n",
       "      <td>0.047292</td>\n",
       "      <td>0.585987</td>\n",
       "      <td>0.687703</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.198919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208940</td>\n",
       "      <td>0.541262</td>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.250081</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.204438</td>\n",
       "      <td>0.405689</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.240213</td>\n",
       "      <td>0.198828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RERE    RNF165  CD049690  BC033982      PHF7     CIDEA     PAPD4  \\\n",
       "0  0.390897  0.191780  0.438119  0.209212  0.258926  0.206795  0.520822   \n",
       "1  0.668317  0.315806  0.438309  0.547825  0.157221  0.055471  0.612500   \n",
       "2  0.492197  0.158484  0.473315  0.452891  0.341374  0.695042  0.534299   \n",
       "3  0.430063  0.101357  0.451425  0.519418  0.263706  0.169905  0.850969   \n",
       "4  0.407779  0.255982  0.490636  0.245708  0.132055  0.047292  0.585987   \n",
       "\n",
       "   AI082173   SLC17A3       SDS  ...  BX115874  BX107598    UGCGL1     VPS72  \\\n",
       "0  0.457770  0.219569  0.388257  ...  0.160475  0.574384  0.409407  0.230384   \n",
       "1  0.580557  0.145330  0.207238  ...  0.393106  0.402749  0.438106  0.297953   \n",
       "2  0.460380  0.214288  0.296164  ...  0.126927  0.279815  0.470394  0.312589   \n",
       "3  0.597362  0.111346  0.273404  ...  0.106922  0.536752  0.423318  0.287952   \n",
       "4  0.687703  0.121704  0.198919  ...  0.208940  0.541262  0.390786  0.250081   \n",
       "\n",
       "      CSMD3    CC2D1A  CB986545     IGSF9  DA110839    FAM71A  \n",
       "0  0.052565  0.237595  0.000000  0.441343  0.249890  0.194661  \n",
       "1  0.058445  0.164547  0.421255  0.570461  0.395704  0.330956  \n",
       "2  0.535862  0.241934  0.552454  0.497964  0.237824  0.404830  \n",
       "3  0.154689  0.261022  0.312797  0.358988  0.132578  0.285221  \n",
       "4  0.079966  0.204438  0.405689  0.347639  0.240213  0.198828  \n",
       "\n",
       "[5 rows x 24368 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_to_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to_df.to_csv(\"all_genes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_all_genes = pd.read_csv(\"all_genes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 24368)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_All_Genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RERE</th>\n",
       "      <th>RNF165</th>\n",
       "      <th>CD049690</th>\n",
       "      <th>BC033982</th>\n",
       "      <th>PHF7</th>\n",
       "      <th>CIDEA</th>\n",
       "      <th>PAPD4</th>\n",
       "      <th>AI082173</th>\n",
       "      <th>SLC17A3</th>\n",
       "      <th>SDS</th>\n",
       "      <th>...</th>\n",
       "      <th>BX115874</th>\n",
       "      <th>BX107598</th>\n",
       "      <th>UGCGL1</th>\n",
       "      <th>VPS72</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>CC2D1A</th>\n",
       "      <th>CB986545</th>\n",
       "      <th>IGSF9</th>\n",
       "      <th>DA110839</th>\n",
       "      <th>FAM71A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390897</td>\n",
       "      <td>0.191780</td>\n",
       "      <td>0.438119</td>\n",
       "      <td>0.209212</td>\n",
       "      <td>0.258926</td>\n",
       "      <td>0.206795</td>\n",
       "      <td>0.520822</td>\n",
       "      <td>0.457770</td>\n",
       "      <td>0.219569</td>\n",
       "      <td>0.388257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160475</td>\n",
       "      <td>0.574384</td>\n",
       "      <td>0.409407</td>\n",
       "      <td>0.230384</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>0.237595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441343</td>\n",
       "      <td>0.249890</td>\n",
       "      <td>0.194661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.668317</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>0.438309</td>\n",
       "      <td>0.547825</td>\n",
       "      <td>0.157221</td>\n",
       "      <td>0.055471</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.580557</td>\n",
       "      <td>0.145330</td>\n",
       "      <td>0.207238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393106</td>\n",
       "      <td>0.402749</td>\n",
       "      <td>0.438106</td>\n",
       "      <td>0.297953</td>\n",
       "      <td>0.058445</td>\n",
       "      <td>0.164547</td>\n",
       "      <td>0.421255</td>\n",
       "      <td>0.570461</td>\n",
       "      <td>0.395704</td>\n",
       "      <td>0.330956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RERE    RNF165  CD049690  BC033982      PHF7     CIDEA     PAPD4  \\\n",
       "0  0.390897  0.191780  0.438119  0.209212  0.258926  0.206795  0.520822   \n",
       "1  0.668317  0.315806  0.438309  0.547825  0.157221  0.055471  0.612500   \n",
       "\n",
       "   AI082173   SLC17A3       SDS  ...  BX115874  BX107598    UGCGL1     VPS72  \\\n",
       "0  0.457770  0.219569  0.388257  ...  0.160475  0.574384  0.409407  0.230384   \n",
       "1  0.580557  0.145330  0.207238  ...  0.393106  0.402749  0.438106  0.297953   \n",
       "\n",
       "      CSMD3    CC2D1A  CB986545     IGSF9  DA110839    FAM71A  \n",
       "0  0.052565  0.237595  0.000000  0.441343  0.249890  0.194661  \n",
       "1  0.058445  0.164547  0.421255  0.570461  0.395704  0.330956  \n",
       "\n",
       "[2 rows x 24368 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_all_genes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
